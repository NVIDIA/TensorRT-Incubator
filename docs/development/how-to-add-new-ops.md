# Adding New Operators

*You may find it helpful to read the [architecture](./architecture.md) documentation*
    *before you start reading this guide.*

Adding new operators to Tripy typically involves making changes in the frontend as well
as in the `FlatIR`. In some cases, the frontend operator can be expressed in terms of existing
`FlatIR` operators, in which case you only need to make changes in the frontend.

Let's take a look at an example of how you might add an `Iota` operator to Tripy.
So that it doesn't clash with Tripy's actual `Iota` implementation, we'll call it
`Theta` instead.

<!-- Use the PYTEST marker since we'll be defining unit tests as part of the guide.
    With this marker, those tests can actually be run under pytest. -->
<!-- Tripy Test: PYTEST Start -->

## Implementation

### `FlatIR` Operator

The `FlatIR` operator is usually the most challenging aspect of implementing operators
in Tripy. The good news is that you might not even need to do this if the low-level operators
you need already exist in the `FlatIR`. And if you do, then it'll only get easier after this!

We'll start by adding a new file under [`tripy/flat_ir/ops`](../../tripy/flat_ir/ops/) called
`theta.py`:

```py
from dataclasses import dataclass

from mlir import ir
from mlir.dialects import stablehlo

from tripy.common.types import ShapeInfo
from tripy.flat_ir.ops.base import BaseFlatIROp


@dataclass(repr=False)
class ThetaOp(BaseFlatIROp):
    dim: int
    shape: ShapeInfo
    dtype: "tripy.dtype"

    def __init__(self, origin_layer, inputs, outputs, dim):
        super().__init__(origin_layer, inputs, outputs)
        self.dim = dim
        self.shape = self.outputs[0].shape
        self.dtype = self.outputs[0].dtype

    def to_mlir(self, operands):
        out_type = self.outputs[0].to_mlir()
        theta_dim = ir.IntegerAttr.get(type=ir.IntegerType.get_signless(64), value=self.dim)
        output = stablehlo.IotaOp(out_type, theta_dim)
        return [output]
```

There are a few important things going on here, so let's break it down:

- Every `FlatIR` operator is implemented as a `dataclass` so that the base
    class can automatically implement several methods by inspecting the child
    class fields at runtime. The `repr=False` is important because the default
    `__repr__` method generated by `dataclass` will be extremely verbose and
    making interactive debugging more difficult.

- The first three arguments to the constructor are for the base class:
    - `origin_layer` is the `Trace` layer that generated this `FlatIR` operator.
    - `inputs` and `outputs` are the `FlatIRTensor`s to this operator.

- The subsequent arguments are for the `ThetaOp` class itself. In this case, there's
    only one:
    - `dim` is the axis along which we'll by applying the operator (which, remember, is just `Iota`!).

- `to_mlir()` is the trickiest bit. As the name implies, the method is meant to lower the
    `FlatIR` operator into MLIR. To figure out which MLIR operators to use, refer to
    [this guide](./mlir-dialect-python-apis.md).

    You'll notice that we pass in `operands`, which are the inputs to the MLIR operator
    but also construct some MLIR tensors ourselves. As you'll soon see, this is asymmetric
    with the design of the `Trace` operators' `to_flat_ir()` where both the input and output
    tensors are passed in. The reason for the asymmetry is that some MLIR operators create
    their own output tensors whereas others need to bind to existing ones. Due to this, we
    leave it to the `FlatIR` operator to convert its own outputs to MLIR if needed.

### Exposing The Operator

One of the principles we follow when writing submodules is that other submodules should
not need to reach into the internals of a submodule to retrieve something they need.

For example, a class which needs to import `ThetaOp` does not need to know where exactly
withing the `flat_ir.ops` module the `ThetaOp` lives - it should be able to just import it
from the submodule.

To make this possible, we need to import the `ThetaOp` into the `flat_ir.ops` submodule.
We can do so by adding the following line into
[`tripy/flat_ir/ops/__init__.py`](../../tripy/flat_ir/ops/__init__.py):

<!-- Tripy Test: IGNORE Start -->

```py
from tripy.flat_ir.ops.theta import ThetaOp
```
<!-- Tripy Test: IGNORE End -->

<!--
Need to simulate the __init__.py changes to make the tests work:
```py
import tripy.flat_ir.ops
tripy.flat_ir.ops.ThetaOp = ThetaOp
```
 -->


## `Trace` Operator And The Public API

Now that we have a `FlatIR` operator, we can implement a `Trace` operator that will use it
along with a public API function. Let's create a new file under
[`tripy/frontend/trace/ops`](../../tripy/frontend/trace/ops/) called `theta.py`.

### `Trace` Operator

First, we'll implement the `Trace` operator itself:

```py
from dataclasses import dataclass

from tripy.common import datatype, device
from tripy.common.types import ShapeInfo
from tripy.frontend.trace.ops.base import BaseTraceOp


@dataclass(repr=False)
class Theta(BaseTraceOp):
    dim: int
    shape: ShapeInfo
    dtype: datatype.dtype

    def infer_shapes(self):
        self.outputs[0].shape = self.shape

    def infer_dtypes(self):
        self.outputs[0].dtype = self.dtype

    def infer_devices(self):
        self.outputs[0].device = device("gpu")

    def to_flat_ir(self, inputs, outputs):
        from tripy.flat_ir.ops import ThetaOp

        ThetaOp(self, inputs, outputs, dim=self.dim)
```

<!-- TODO: Update this documentation once dynamic shapes are implemented -->
**If you're seeing this and dynamic shapes have already been implemented, please notify us so we**
    **can update the documentation.**

Once again, let's break this down:

- Just like with `FlatIR` operators, all `Trace` operators are implemented as `dataclass`es.
    As before, we want `repr=False` here.

- We do *not* need to define a constructor and can rely on the default implementation provided by `dataclass`.

- There are a few different methods we implement:
    - `infer_shapes()` populates the shapes of the output `TraceTensor`s. For most operators, the output
        shapes will depend on the shapes of `self.inputs`. In our cases, since `Theta` generates a tensor,
        there is no input tensor.

    - **[Optional]** `infer_dtypes()` populates the data types of the output `TraceTensor`s. The default implementation
        copies the input data types if they are all the same, so you may not need to implement this.

    - **[Optional]** `infer_devices()` populates the devices of the output `TraceTensor`s. The default implementation
        copies the input devices if they are all the same, so you may not need to implement this either.

    - `to_flat_ir()` translates the `Trace` operator to a subgraph of one or more `FlatIR` operators.
        In our case, it's just a 1:1 mapping to the `ThetaOp` we created earlier.

        *Note that we import the `FlatIR` operator within the function call - this is to avoid circular*
            *dependencies.*

        This code may look a bit confusing; for more details, look at [this section](./architecture.md#lowering-to-flatir)
        in the architecture document.


### Public API

Next, we can define the public interface. Since our public interface maps 1:1 with the `Trace`
operator we just implemented, we'll add it in the same file.

First, we need to add some extra imports to the top of the file:
```py
from tripy import utils
from tripy.common.exception import raise_error
```

Now we can implement the public API function:

```py
def theta(shape: ShapeInfo, dim: int = 0, dtype: datatype.dtype = datatype.float32) -> "tripy.Tensor":
    """
    Fills an output tensor with consecutive values starting from zero along the given dimension.

    Args:
        shape: The desired shape.
        dim: Dimension along which to perform the theta operation.
            This cannot exceed the rank of the specified shape.
        dtype: The desired data type.

    Returns:
        A tensor of shape ``shape`` and data type ``dtype``.

    .. code-block:: python
        :linenos:
        :caption: Example

        output = tp.theta([3])

        assert np.array_equal(output.numpy(), np.arange(0, 3, dtype=np.float32))
    """
    from tripy.frontend import Tensor

    if dim < 0 or dim >= len(shape):
        raise_error(
            "Invalid theta dim.",
            details=[
                "theta dim must be satisfy 0 <= dim < rank(shape), got dim=",
                dim,
                ", while rank of shape is ",
                len(shape),
            ],
        )
    return Tensor.build([], Theta, dim, utils.to_dims(shape), dtype)
```

You know the drill - let's break it down:

- For any public facing interfaces, we have documentation requirements which you can read
    about [here](../../docs/README.md#docstrings). The docstring we've implemented above
    adheres to all of these requirements. Non-compliant docstrings will, in most cases,
    cause test failures; however, you should still manually ensure you're writing high-quality
    docstrings.

    The examples in docstrings are run as part of our tests, so you should also add
    `assert`ions to make sure things are functionally correct. In this case, we check
    that the `output` we create in the code example is what we expect.

- The body of the function is fairly simple:

    - We first validate the input parameters. By using `raise_error`, we can ensure that
        the generated error will be nicely formatted. Additionally, if any of the items in
        the `details` argument contain stack information, it will be displayed automatically.

    - Next we build a frontend `Tensor`. The `build()` function is responsible for constructing
        the `Trace` operator. All of the arguments that follow the `Trace` operator type argument
        (i.e. `Theta`) are forwarded directly to the constructor of the `Trace` operator.

*NOTE: Here we're providing a free function, but if we wanted to instead provide the API as a*
    *method of `Tensor`, we would decorate the function with the `TENSOR_METHOD_REGISTRY`.*


### Exposing The Operator

Similarly to the `FlatIR` operator, we need to import `Theta` and `theta()` into the
`frontend.trace.ops` submodule. We can do so by adding the following line into
[`tripy/frontend/trace/ops/__init__.py`](../../tripy/frontend/trace/ops/__init__.py):

<!-- Tripy Test: IGNORE Start -->

```py
from tripy.frontend.trace.ops.theta import Theta, theta
```
<!-- Tripy Test: IGNORE End -->

<!--
Need to simulate the __init__.py changes to make the tests work:
```py
import tripy.frontend.trace.ops
tripy.frontend.trace.ops.Theta = Theta
tripy.frontend.trace.ops.theta = theta
```
 -->


We want to expose the public interface into the top-level module so we can call it with
`tp.theta`, so let's bubble it up through the submodules.

In [`tripy/frontend/__init__.py`](../../tripy/frontend/__init__.py), add:

<!-- Tripy Test: IGNORE Start -->

```py
from tripy.frontend.trace.ops import theta
```
<!-- Tripy Test: IGNORE End -->

<!--
Need to simulate the __init__.py changes to make the tests work:
```py
import tripy.frontend
tripy.frontend.theta = theta
```
 -->


**Make sure to update the `__all__` variable so that the documentation displays**
**the correct module names.**

Then in [`tripy/__init__.py`](../../tripy/__init__.py), add:

<!-- Tripy Test: IGNORE Start -->

```py
from tripy.frontend import theta
```
<!-- Tripy Test: IGNORE End -->

<!--
Need to simulate the __init__.py changes to make the tests work:
```py
import tripy
tripy.theta = theta
```
 -->

**Once again, make sure to update the `__all__` variable.**


## Documentation

Now that we've added the public API, let's make sure it appears in the documentation.
In our example, the best place to document the API is in the
[`tensor_initialization.rst` file](../tensor/tensor_initialization.rst).

All we need to do is add another entry there:
```rst
.. autofunction:: tripy.zeros_like
```

See the [documentation README](../README.md) for more details on the public documentation.

## Testing

Now that we've implemented our operator, let's write tests for it. The structure of the
[`tests/`](../../tests/) directory mirrors that of the [`tripy/`](../../tripy/) directory
(you can read more about that [here](../../tests/README.md)). We need to test both the `FlatIR`
and `Trace` operators.

### Testing The `FlatIR` Operator

When testing our `FlatIR` operator, we essentially need to test two things:

1. Is the string reprensetation of the operator correct? We need to make sure it is since this
    is what will appear in the `FlatIR` dumps.

2. Is the translation to MLIR correct?

Since we implemented the `FlatIR` operator in [`tripy/flat_ir/ops`](../../tripy/flat_ir/ops/), we'll
add the corresponding test under [`tests/flat_ir/ops`](../../tests/flat_ir/ops/). Create a new file
there called `test_theta.py`.

We'll start by defining a pytest fixture that will generate a `FlatIR` containing a `ThetaOp` for us.
To do so, we can simply use the public API, generate a `Trace`, and convert to `FlatIR`:

```py
import pytest

import tripy as tp
from tripy.frontend.trace import Trace


@pytest.fixture
def flat_ir():
    out = tp.theta((2, 3))
    out.name = "out"

    trace = Trace([out])
    yield trace.to_flat_ir()
```

Before we add the tests, we need to add some more imports to the top of our file:

```py
from tests import helper
from tripy.flat_ir.ops import IotaOp
```

Now we can create a test class with our two tests:

```py
class TestThetaOp:
    def test_str(self, flat_ir):
        Theta = flat_ir.ops[-1]
        assert isinstance(Theta, ThetaOp)
        assert (
            str(Theta)
            == "out: [shape=(2, 3,), dtype=(float32), loc=(gpu:0)] = ThetaOp(dim=0, shape=(2, 3), dtype=float32)"
        )

    def test_mlir(self, flat_ir):
        helper.check_mlir(
            flat_ir.to_mlir(),
            """
            module {
                func.func @main() -> tensor<2x3xf32> {
                    %0 = stablehlo.iota dim = 0 : tensor<2x3xf32>
                    return %0 : tensor<2x3xf32>
                }
            }
            """,
        )
```

- `test_str()` tests the string representation of our `FlatIR` operator. This may be hard to predict, so we
    suggest that you first `print(str(Theta))`, check if it looks correct, and then add the corresponding
    string to the test.

- `test_mlir()` tests conversion to MLIR by checking the generated MLIR module code. Once again, this is
    difficult to predict ahead of time, so you should print the MLIR module once, check if it looks correct,
    and then update the test accordingly.


### Testing The Trace Operator And Public API

Since we implemented our `Trace` operator and public API in
[`tripy/frontend/trace/ops`](../../tripy/frontend/trace/ops/), we'll add the test under
[`tests/frontend/trace/ops`](../../tests/frontend/trace/ops/).
Create a new file there called `test_theta.py`:


```py
import tripy as tp
from tests import helper
from tripy.frontend.trace.ops import Theta


class TestTheta:
    def test_op_func(self):
        a = tp.theta([2, 3])
        assert isinstance(a, tp.Tensor)
        assert isinstance(a.op, Theta)


    def test_invalid_dim(self):
        with helper.raises(tp.TripyException, match="Invalid theta dim."):
            tp.theta([2, 3], dim=3)
```

- `test_op_func()` ensures that the public API function creates a frontend `Tensor`
    and populates it with the right `Trace` operator.

- You should also include negative tests for anything that is expected to fail in the frontend.
    In our case, we just have `test_invalid_dim`, which ensures that we emit an error if the `dim`
    parameter is outside the allowed range.


### Integration Tests

The code examples in the docstring of the public API serve as good sanity integration tests.
However, you should still add separate integration tests to get better coverage.

Our docstring covers the 1D case, so let's add an integration test to cover the multidimensional case.
Create a new file called `test_theta.py` under [`tests/integration`](../../tests/integration/):

```py
import numpy as np

import tripy as tp


def test_multi_dimensional():
    output = tp.theta([2, 3], dim=1)
    expected = np.broadcast_to(np.arange(0, 3, dtype=np.float32), (2, 3))

    assert np.array_equal(output.numpy(), expected)
```

## Done!

If you've reached this point, you have successfully added a new operation to
Tripy. Congratulations!

<!-- Tripy Test: PYTEST End -->
