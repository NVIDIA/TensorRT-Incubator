{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Image Classificiation\n",
    "\n",
    "This notebook aims to demonstrate the implementation of a ResNet50 model using `tripy`. It implements the architecture, \n",
    "loads pretrained weights, and runs predictions on a sample dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets matplotlib pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tripy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "import tripy as tp\n",
    "\n",
    "\n",
    "class ResNetConvLayer(tp.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_dims: Tuple[int, int],\n",
    "        stride: Tuple[int, int] = (1, 1),\n",
    "        padding: Tuple[Tuple[int, int], Tuple[int, int]] = ((0, 0), (0, 0)),\n",
    "        activation: bool = True,\n",
    "    ):\n",
    "        \"\"\"Convolutional layer with batch normalization and optional\n",
    "        ReLU activation.\"\"\"\n",
    "        super(ResNetConvLayer, self).__init__()\n",
    "        self.convolution = tp.Conv(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_dims=kernel_dims,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.normalization = tp.BatchNorm(out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        x = self.convolution(x)\n",
    "        x = self.normalization(x)\n",
    "        if self.activation:\n",
    "            x = tp.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetShortCut(tp.Module):\n",
    "    def __init__(\n",
    "        self, in_channels: int, out_channels: int, stride: Tuple[int, int]\n",
    "    ):\n",
    "        \"\"\"1x1 convolution and batch normalization for input and output channel\n",
    "        dimension matching in ResNetBottleNeckLayer.\"\"\"\n",
    "        super(ResNetShortCut, self).__init__()\n",
    "        self.convolution = tp.Conv(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_dims=(1, 1),\n",
    "            stride=stride,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.normalization = tp.BatchNorm(out_channels)\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        x = self.convolution(x)\n",
    "        x = self.normalization(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEmbeddings(tp.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Applies an initial convolution and max-pooling operation to reduce\n",
    "        dimensions and prepare input for the encoder.\n",
    "        \"\"\"\n",
    "        super(ResNetEmbeddings, self).__init__()\n",
    "        self.embedder = ResNetConvLayer(\n",
    "            3,\n",
    "            64,\n",
    "            kernel_dims=(7, 7),\n",
    "            stride=(2, 2),\n",
    "            padding=((3, 3), (3, 3)),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        x = self.embedder(x)\n",
    "        x = tp.maxpool(\n",
    "            x,\n",
    "            kernel_dims=(3, 3),\n",
    "            stride=(2, 2),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetBottleNeckLayer(tp.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bottleneck_channels: int,\n",
    "        stride: Tuple[int, int],\n",
    "    ):\n",
    "        \"\"\"Consists of a ResNetShortCut layer for dimension matching and\n",
    "        three ResNetConvLayers for residual learning.\"\"\"\n",
    "        super(ResNetBottleNeckLayer, self).__init__()\n",
    "\n",
    "        self.shortcut = (\n",
    "            ResNetShortCut(in_channels, out_channels, stride)\n",
    "            if in_channels != out_channels or stride != (1, 1)\n",
    "            else lambda x: x\n",
    "        )\n",
    "        self.layer = [\n",
    "            ResNetConvLayer(\n",
    "                in_channels,\n",
    "                bottleneck_channels,\n",
    "                kernel_dims=(1, 1),\n",
    "                stride=(1, 1),\n",
    "            ),\n",
    "            ResNetConvLayer(\n",
    "                bottleneck_channels,\n",
    "                bottleneck_channels,\n",
    "                kernel_dims=(3, 3),\n",
    "                stride=stride,\n",
    "                padding=((1, 1), (1, 1)),\n",
    "            ),\n",
    "            ResNetConvLayer(\n",
    "                bottleneck_channels,\n",
    "                out_channels,\n",
    "                kernel_dims=(1, 1),\n",
    "                stride=(1, 1),\n",
    "                activation=False,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        self.activation = tp.relu\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        identity = self.shortcut(x)\n",
    "        for layer in self.layer:\n",
    "            x = layer(x)\n",
    "        x = x + identity\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetStage(tp.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bottleneck_channels: int,\n",
    "        stride: Tuple[int, int],\n",
    "    ):\n",
    "        \"\"\"Contains multiple bottleneck layers, increasing channels and reducing\n",
    "        spatial dimensions.\"\"\"\n",
    "        super(ResNetStage, self).__init__()\n",
    "        self.layers = []\n",
    "        for i in range(num_layers):\n",
    "            layer = ResNetBottleNeckLayer(\n",
    "                in_channels if i == 0 else out_channels,\n",
    "                out_channels,\n",
    "                bottleneck_channels,\n",
    "                stride if i == 0 else (1, 1),\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetEncoder(tp.Module):\n",
    "    def __init__(\n",
    "        self, layers_config: List[Tuple[int, int, int, Tuple[int, int]]]\n",
    "    ):\n",
    "        \"\"\"Comprises multiple stages of bottleneck layers to extract abstract\n",
    "        features from the input.\"\"\"\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "        self.stages = []\n",
    "        in_channels = 64\n",
    "        for _, (\n",
    "            num_layers,\n",
    "            out_channels,\n",
    "            bottleneck_channels,\n",
    "            stride,\n",
    "        ) in enumerate(layers_config):\n",
    "            stage = ResNetStage(\n",
    "                num_layers,\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                bottleneck_channels,\n",
    "                stride,\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            in_channels = out_channels\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        for stage in self.stages:\n",
    "            x = stage(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetModel(tp.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Combines ResNetEmbeddings and ResNetEncoder to create the backbone\n",
    "        for feature extraction.\"\"\"\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.embedder = ResNetEmbeddings()\n",
    "        layers_config = [\n",
    "            (3, 256, 64, (1, 1)),\n",
    "            (4, 512, 128, (2, 2)),\n",
    "            (6, 1024, 256, (2, 2)),\n",
    "            (3, 2048, 512, (2, 2)),\n",
    "        ]\n",
    "        self.encoder = ResNetEncoder(layers_config)\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        x = self.embedder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = tp.avgpool(\n",
    "            x, kernel_dims=(7, 7), stride=(7, 7)\n",
    "        )  # output size will be (1, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetClassifier(tp.Module):\n",
    "    def __init__(self, num_classes: int = 1000):\n",
    "        \"\"\"Combines the backbone ResNetModel and a classifier head for\n",
    "        outputting class probabilities.\"\"\"\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.resnet = ResNetModel()\n",
    "        self.classifier = tp.Sequential(\n",
    "            lambda x: tp.flatten(x, start_dim=1),\n",
    "            tp.Linear(2048, num_classes),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        features = self.resnet(x)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Tripy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripy_model = ResNetClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Weights to Tripy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ResNetForImageClassification\n",
    "\n",
    "# Load the pretrained ResNet50 model from Hugging Face\n",
    "resnet_pretrained = ResNetForImageClassification.from_pretrained(\n",
    "    \"microsoft/resnet-50\"\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_weights(model, pretrained_state_dict):\n",
    "    model_state_dict_keys = set(model.state_dict().keys())\n",
    "    model_dict = {}\n",
    "\n",
    "    # Convert each weight to a tp.Parameter and update the model's state dict\n",
    "    for k, v in pretrained_state_dict.items():\n",
    "        if \"num_batches_tracked\" in k:\n",
    "            continue  # Skip num_batches_tracked since it is not needed for\n",
    "            # inference (tp.BatchNorm does not support)\n",
    "\n",
    "        assert k in model_state_dict_keys\n",
    "        model_dict[k] = tp.Parameter(v.contiguous())\n",
    "\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Load pretrained weights to tripy model\n",
    "tripy_model = load_pretrained_weights(\n",
    "    tripy_model,\n",
    "    pretrained_state_dict=resnet_pretrained.state_dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Tripy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_classifier(input):\n",
    "    \"\"\"Inference function to compile. Runs forward path\n",
    "    and returns argmax of output logits.\"\"\"\n",
    "    logits = tripy_model(input)\n",
    "    return tp.argmax(logits)\n",
    "\n",
    "\n",
    "input_shape = [1, 3, 224, 224]\n",
    "compiled_resnet_classifier = tp.compile(\n",
    "    resnet_classifier,\n",
    "    args=[tp.InputInfo(input_shape, dtype=tp.float32)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tripy Demo\n",
    "\n",
    "Now we will test our ResNet50 classification model on a few sample images for image classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "from datasets import load_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Sample image indices to classify\n",
    "idxs = [6, 44, 34, 25, 105]\n",
    "labels = [\n",
    "    \"apron\",\n",
    "    \"medicine chest, medicine cabinet\",\n",
    "    \"mountain bike, all-terrain bike, off-roader\",\n",
    "    \"lifeboat\",\n",
    "    \"disk brake, disc brake\",\n",
    "]\n",
    "\n",
    "# Load the image dataset\n",
    "dataset = load_dataset(\"comet-team/coco-500\", split=\"train\")\n",
    "\n",
    "# Load the image processor for image pre-processing\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "fig, axes = plt.subplots(1, len(idxs), figsize=(15, 3))\n",
    "\n",
    "# Loop through each index and corresponding subplot\n",
    "for ax, nid, label in zip(axes, idxs, labels):\n",
    "    image = dataset[nid][\"Image\"]\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Pre-process the image for inference\n",
    "    processed_image = processor(image, return_tensors=\"np\")[\"pixel_values\"]\n",
    "    tp_image = tp.Tensor(\n",
    "        processed_image,\n",
    "        dtype=tp.float32,\n",
    "        device=tp.device(\"gpu\"),\n",
    "    )\n",
    "\n",
    "    # Run inference with compiled model and get predicted label\n",
    "    label_idx = compiled_resnet_classifier(tp_image)\n",
    "    predicted_label = resnet_pretrained.config.id2label[label_idx.tolist()]\n",
    "\n",
    "    assert predicted_label == label, f\"{predicted_label} vs {label}\"\n",
    "    ax.set_title(predicted_label, fontsize=10, fontweight=\"bold\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.suptitle(\n",
    "    \"Visualized ResNet50 Predictions\",\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    "    y=1.05,\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "nbreg": {
   "diff_ignore": [
    "/cells/*/outputs/",
    "/cells/*/execution_count"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
