{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Image Classificiation with `tripy` - An Implementation and Demo\n",
    "\n",
    "This notebook aims to demonstrate the implementation of a ResNet50 model using `tripy`. We'll explore the architecture, \n",
    "load pretrained weights, and run predictions on a sample dataset, showcasing how `tripy` can be used effectively for inference of ResNet50 based image classification model.\n",
    "\n",
    "### Objectives:\n",
    "1. Implement ResNet50 using `tripy` and load pretrained weights.\n",
    "2. Run predictions on sample images and visualize results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "install neccessary libraries, load pretrained resnet50 weights and the inference dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets matplotlib pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import torch\n",
    "from transformers import ResNetForImageClassification, AutoImageProcessor\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the pretrained ResNet50 model from Hugging Face\n",
    "resnet_pretrained = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "resnet_pretrained.eval()\n",
    "resnet_pretrained = resnet_pretrained.to('cuda')\n",
    "\n",
    "# Load the image processor\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "# Load a sample image from the dataset\n",
    "dataset = load_dataset(\"comet-team/coco-500\", split=\"train\")\n",
    "idx = 103\n",
    "image = dataset[idx]['Image']\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "inputs = processor(image, return_tensors=\"pt\")['pixel_values'].to('cuda')\n",
    "\n",
    "# Run the image through the model\n",
    "with torch.no_grad():\n",
    "    logits = resnet_pretrained(inputs).logits\n",
    "\n",
    "# Get the predicted label\n",
    "predicted_label = logits.argmax(-1).item()\n",
    "print(f\"Predicted Label: {resnet_pretrained.config.id2label[predicted_label]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tripy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tripy as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define:\n",
    "\n",
    "1. **ResNet Building Blocks**:\n",
    "   - **`ResNetConvLayer`**: A configurable convolutional layer with batch normalization and optional ReLU activation.\n",
    "   - **`ResNetBottleNeckLayer`**: A layer consisting of three `ResNetConvLayer`s with a shortcut connection for residual learning.\n",
    "\n",
    "2. **`ResNetStage`**:\n",
    "   - Each stage contains multiple bottleneck layers, increasing channels and reducing spatial dimensions.\n",
    "\n",
    "3. **`ResNetEmbeddings`**:\n",
    "   - Applies an initial convolution and max-pooling operation to reduce dimensions and prepare input for the encoder.\n",
    "\n",
    "4. **`ResNetEncoder`**:\n",
    "   - Comprises multiple stages of bottleneck layers to extract abstract features from the input.\n",
    "\n",
    "5. **`ResNetModel` Backbone**:\n",
    "   - Combines `ResNetEmbeddings` and `ResNetEncoder` to create the backbone for feature extraction.\n",
    "\n",
    "6. **`ResNetClassifier`**:\n",
    "   - Combines the backbone (`ResNetModel`) and a classifier head for outputting class probabilities.\n",
    "\n",
    "\n",
    "### Our final image classification model is visualized below:\n",
    "\n",
    "```text\n",
    "Input Image (224 x 224 x 3)\n",
    "        |\n",
    "        v\n",
    "+------------------------------------------------------------------------------+\n",
    "|                               ResNetClassifier                               |\n",
    "|                                                                              |\n",
    "|   +----------------------------------------------------------+               |\n",
    "|   |                    ResNetModel (Backbone)                |               |\n",
    "|   |                                                          |               |\n",
    "|   | +----------------------+   +-------------------------+   |               |\n",
    "|   | | ResNetEmbeddings     |   | ResNetEncoder           |   |               |\n",
    "|   | | Conv7x7, 64, Stride 2|-->| (4 stages with          |   |               |\n",
    "|   | | MaxPool 3x3, Stride 2|   | bottlenecks):           |   |               |\n",
    "|   | | Output: (56 x 56 x 64)|  | - Stage 1: (3 layers)   |   |               |\n",
    "|   | +----------------------+   | - Stage 2: (4 layers)   |   |               |\n",
    "|   |                            | - Stage 3: (6 layers)   |   |               |\n",
    "|   |                            | - Stage 4: (3 layers)   |   |               |\n",
    "|   |                            | Output: (1 x 1 x 2048)  |   |               |\n",
    "|   |                            +-------------------------+   |               |\n",
    "|   |                                            |             |               |\n",
    "|   |                                            v             |               |\n",
    "|   |  +----------------------------------------------------+  |               |\n",
    "|   |  | Average Pooling (kernel 7x7, strid 7x7)            |  |               |\n",
    "|   |  | Output: (1 x 1 x 2048)                             |  |               |\n",
    "|   |  +----------------------------------------------------+  |               |\n",
    "|                               |                                              |\n",
    "|                               v                                              |\n",
    "|   +-------------------------------------------------------+                  |\n",
    "|   |                   Classifier                          |                  |\n",
    "|   |                 Fully Connected Layer                 |                  | -> Ouput classes probablity (1000)\n",
    "|   |               Output: (1000 classes)                  |                  |\n",
    "|   +-------------------------------------------------------+                  |\n",
    "+-------------------------------------------------------------------------------+\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetConvLayer(tp.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_dims, stride=(1, 1), padding=((0, 0), (0, 0)), activation=True):\n",
    "        super(ResNetConvLayer, self).__init__()\n",
    "        self.convolution = tp.Conv(\n",
    "            in_channels, out_channels, kernel_dims=kernel_dims,\n",
    "            stride=stride, padding=padding, bias=False\n",
    "        )\n",
    "        self.normalization = tp.BatchNorm(out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.convolution(x)\n",
    "        x = self.normalization(x)\n",
    "        if self.activation:\n",
    "            x = tp.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNetShortCut(tp.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(ResNetShortCut, self).__init__()\n",
    "        self.convolution = tp.Conv(\n",
    "            in_channels, out_channels, kernel_dims=(1, 1),\n",
    "            stride=stride, bias=False\n",
    "        )\n",
    "        self.normalization = tp.BatchNorm(out_channels)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.convolution(x)\n",
    "        x = self.normalization(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBottleNeckLayer(tp.Module):\n",
    "    def __init__(self, in_channels, out_channels, bottleneck_channels, stride):\n",
    "        super(ResNetBottleNeckLayer, self).__init__()\n",
    "\n",
    "        self.shortcut = ResNetShortCut(in_channels, out_channels, stride) if in_channels != out_channels or stride != (1, 1) else lambda x: x\n",
    "        self.layer = [\n",
    "            ResNetConvLayer(in_channels, bottleneck_channels, kernel_dims=(1, 1), stride=(1, 1)),\n",
    "            ResNetConvLayer(bottleneck_channels, bottleneck_channels, kernel_dims=(3, 3), stride=stride, padding=((1, 1), (1, 1))),\n",
    "            ResNetConvLayer(bottleneck_channels, out_channels, kernel_dims=(1, 1), stride=(1, 1), activation=False),\n",
    "        ]\n",
    "\n",
    "        self.activation = tp.relu\n",
    "\n",
    "    def __call__(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        for layer in self.layer:\n",
    "            x = layer(x)\n",
    "        x = x + identity\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class ResNetStage(tp.Module):\n",
    "    def __init__(self, num_layers, in_channels, out_channels, bottleneck_channels, stride):\n",
    "        super(ResNetStage, self).__init__()\n",
    "        self.layers = []\n",
    "        for i in range(num_layers):\n",
    "            layer = ResNetBottleNeckLayer(\n",
    "                in_channels if i == 0 else out_channels,\n",
    "                out_channels, bottleneck_channels,\n",
    "                stride if i == 0 else (1, 1)\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEmbeddings(tp.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetEmbeddings, self).__init__()\n",
    "        self.embedder = ResNetConvLayer(3, 64, kernel_dims=(7, 7), stride=(2, 2), padding=((3, 3), (3, 3)))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.embedder(x)\n",
    "        x = tp.maxpool(x, kernel_dims=(3, 3), stride=(2, 2), padding=((1, 1), (1, 1)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetEncoder(tp.Module):\n",
    "    def __init__(self, layers_config):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "        self.stages = []\n",
    "        in_channels = 64\n",
    "        for _, (num_layers, out_channels, bottleneck_channels, stride) in enumerate(layers_config):\n",
    "            stage = ResNetStage(num_layers, in_channels, out_channels, bottleneck_channels, stride)\n",
    "            self.stages.append(stage)\n",
    "            in_channels = out_channels\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for stage in self.stages:\n",
    "            x = stage(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetModel(tp.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.embedder = ResNetEmbeddings()\n",
    "        layers_config = [\n",
    "            (3, 256, 64, (1, 1)),\n",
    "            (4, 512, 128, (2, 2)),\n",
    "            (6, 1024, 256, (2, 2)),\n",
    "            (3, 2048, 512, (2, 2)),\n",
    "        ]\n",
    "        self.encoder = ResNetEncoder(layers_config)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.embedder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = tp.avgpool(x, kernel_dims=(7, 7), stride=(7, 7)) # output size will be (1, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClassifier(tp.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.resnet = ResNetModel()\n",
    "        self.classifier = tp.Linear(2048, num_classes)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        features = self.resnet(x)\n",
    "        features = tp.flatten(features, start_dim=1)\n",
    "        output = self.classifier(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Tripy model\n",
    "tripy_model = ResNetClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights to Tripy Model\n",
    "\n",
    "First we ensure all state dict keys match and then we load the pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_weights_tp(model, pretrained_state_dict):\n",
    "    \"\"\"\n",
    "    This function loads weights from a state_dict into the custom TPResNet model,\n",
    "    converting them into tp.Parameter before loading.\n",
    "    \"\"\"\n",
    "    model_dict = model.state_dict()  # Get the model's state dict\n",
    "\n",
    "    # Convert each weight to a tp.Parameter and update the model's state dict\n",
    "    for k, v in pretrained_state_dict.items():\n",
    "        if 'num_batches_tracked' in k:\n",
    "            continue    # Skip num_batches_tracked since it is not needed for inference (tp.BatchNorm does not support)\n",
    "        if 'classifier' in k:\n",
    "            k = k.replace('1.', '') # Remove extra 1 (slight naming mismtach)\n",
    "\n",
    "        assert k in set(model_dict.keys())\n",
    "        new_v = tp.Parameter(v.contiguous())\n",
    "        model_dict[k] = new_v \n",
    "\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "pretrained_state_dict = resnet_pretrained.state_dict()\n",
    "tripy_model = load_pretrained_weights_tp(tripy_model, pretrained_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compile the model with static input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [1, 3, 224, 224]\n",
    "compiled_model = tp.compile(tripy_model, args=[tp.InputInfo(input_shape, dtype=tp.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a dummy forward path\n",
    "x = tp.ones(input_shape, dtype=tp.float32)\n",
    "compiled_output = compiled_model(x)\n",
    "compiled_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tripy Demo\n",
    "\n",
    "Now we will test our tripy resnet50 classification model on a few sample images for image classification task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the image for Tripy\n",
    "processed_image = processor(image, return_tensors=\"np\")['pixel_values']\n",
    "tp_image = tp.Tensor(processed_image, dtype=tp.float32, device=tp.device(\"gpu\"))\n",
    "tp_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the image through the model\n",
    "tp_logits = compiled_model(tp_image)\n",
    "tp_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted label\n",
    "tp_predicted_label = torch.argmax(torch.from_dlpack(tp_logits), -1).tolist()[0]\n",
    "print(f\"Predicted Label: {resnet_pretrained.config.id2label[tp_predicted_label]}\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tp_pred(model, image, processor):\n",
    "    processed_image = processor(image, return_tensors=\"np\")['pixel_values']\n",
    "    tp_image = tp.Tensor(processed_image, dtype=tp.float32, device=tp.device(\"gpu\"))\n",
    "    tp_logits = model(tp_image)\n",
    "    return torch.argmax(torch.from_dlpack(tp_logits), -1).tolist()[0]\n",
    "\n",
    "def get_exact_answer(model, image, processor):\n",
    "    inputs = processor(image, return_tensors=\"pt\")['pixel_values'].to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_pretained = model(inputs).logits\n",
    "\n",
    "    return logits_pretained.argmax(-1).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a few more classification examplesusing tripy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idxs = [6, 44, 34, 25, 105]\n",
    "fig, axes = plt.subplots(1, len(idxs), figsize=(15, 3)) \n",
    "\n",
    "# Loop through each index and corresponding subplot\n",
    "for ax, nid in zip(axes, idxs):\n",
    "    image = dataset[nid]['Image']\n",
    "    ax.imshow(image)\n",
    "    tp_predicted_label = get_tp_pred(compiled_model, image, processor)\n",
    "    exact_answer = get_exact_answer(resnet_pretrained, image, processor)\n",
    "\n",
    "    pred = resnet_pretrained.config.id2label[tp_predicted_label]\n",
    "    exact = resnet_pretrained.config.id2label[exact_answer]\n",
    "\n",
    "    assert pred == exact, f\"{pred} vs {exact}\"\n",
    "\n",
    "    ax.set_title(pred, fontsize=10, fontweight='bold') \n",
    "    ax.axis('off') \n",
    "    ax.set_xticks([]) \n",
    "    ax.set_yticks([]) \n",
    "\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.suptitle(\"Visualized Predictions\", fontsize=16, fontweight='bold', y=1.05)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
