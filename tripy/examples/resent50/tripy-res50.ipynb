{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 with `tripy` - An Implementation and Demo\n",
    "\n",
    "This notebook aims to demonstrate the implementation of a ResNet50 model using `tripy`. We'll explore the architecture, \n",
    "load pretrained weights, and run predictions on a sample dataset, showcasing how `tripy` can be used effectively for deep learning tasks.\n",
    "\n",
    "### Objectives:\n",
    "1. Implement ResNet50 using `tripy` and load pretrained weights.\n",
    "2. Run predictions on sample images and visualize results.\n",
    "3. Provide an intuitive and educational overview of ResNet components and their implementation in `tripy`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "install neccessary libraries, load pretrained resnet50 weights and the inference dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets matplotlib pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import torch\n",
    "from transformers import ResNetForImageClassification, AutoImageProcessor\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the pretrained ResNet50 model from Hugging Face\n",
    "resnet_pretrained = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "resnet_pretrained.eval()\n",
    "resnet_pretrained = resnet_pretrained.to('cuda')\n",
    "\n",
    "# Load the image processor\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "# Load a sample image from the dataset\n",
    "dataset = load_dataset(\"rafaelpadilla/coco2017\", split=\"val\")\n",
    "idx = 103  # You can choose any index\n",
    "image = dataset[idx]['image']\n",
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "inputs = processor(image, return_tensors=\"pt\")['pixel_values'].to('cuda')\n",
    "\n",
    "# Run the image through the model\n",
    "with torch.no_grad():\n",
    "    logits = resnet_pretrained(inputs).logits\n",
    "\n",
    "# Get the predicted label\n",
    "predicted_label = logits.argmax(-1).item()\n",
    "print(f\"Predicted Label: {resnet_pretrained.config.id2label[predicted_label]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tripy Implementation\n",
    "Now we will implement the model definition in tripy. Most of the resenet50 modules are supported by tripy, but there are a few missing which we will custom define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tripy as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BatchNorm(tp.Module):\n",
    "#     def __init__(self, num_features, eps=1e-5):\n",
    "#         super(BatchNorm, self).__init__()\n",
    "#         self.num_features = num_features\n",
    "#         self.eps = eps\n",
    "\n",
    "#         # Learnable parameters (scale and shift)\n",
    "#         self.weight = tp.Parameter(tp.ones((1, num_features, 1, 1), dtype=tp.float32))\n",
    "#         self.bias = tp.Parameter(tp.zeros((1, num_features, 1, 1), dtype=tp.float32))\n",
    "\n",
    "#         # Running statistics (not updated during training)\n",
    "#         self.running_mean = tp.Parameter(tp.zeros((1, num_features, 1, 1), dtype=tp.float32))\n",
    "#         self.running_var = tp.Parameter(tp.ones((1, num_features, 1, 1), dtype=tp.float32))\n",
    "#         self.num_batches_tracked = tp.Parameter(tp.Tensor(0, dtype=tp.int64))\n",
    "\n",
    "#     def __call__(self, x):\n",
    "#         # Normalize the input\n",
    "#         x = (x - self.running_mean) / tp.sqrt(self.running_var + self.eps)\n",
    "\n",
    "#         # Apply the learned scaling (weight) and shifting (bias)\n",
    "#         x = self.weight * x + self.bias\n",
    "\n",
    "#         return x\n",
    "\n",
    "\n",
    "class ResNetConvLayer(tp.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_dims, stride=(1, 1), padding=((0, 0), (0, 0)), activation=True):\n",
    "        super(ResNetConvLayer, self).__init__()\n",
    "        self.convolution = tp.Conv(\n",
    "            in_channels, out_channels, kernel_dims=kernel_dims,\n",
    "            stride=stride, padding=padding, bias=False\n",
    "        )\n",
    "        self.normalization = BatchNorm(out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.convolution(x)\n",
    "        x = self.normalization(x)\n",
    "        if self.activation:\n",
    "            x = tp.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetShortCut(tp.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(ResNetShortCut, self).__init__()\n",
    "        self.convolution = tp.Conv(\n",
    "            in_channels, out_channels, kernel_dims=(1, 1),\n",
    "            stride=stride, bias=False\n",
    "        )\n",
    "        self.normalization = BatchNorm(out_channels)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.convolution(x)\n",
    "        x = self.normalization(x)\n",
    "        return x\n",
    "\n",
    "class ResNetBottleNeckLayer(tp.Module):\n",
    "    def __init__(self, in_channels, out_channels, bottleneck_channels, stride):\n",
    "        super(ResNetBottleNeckLayer, self).__init__()\n",
    "\n",
    "        self.shortcut = ResNetShortCut(in_channels, out_channels, stride) if in_channels != out_channels or stride != (1, 1) else lambda x: x\n",
    "        self.layer = [\n",
    "            ResNetConvLayer(in_channels, bottleneck_channels, kernel_dims=(1, 1), stride=(1, 1)),\n",
    "            ResNetConvLayer(bottleneck_channels, bottleneck_channels, kernel_dims=(3, 3), stride=stride, padding=((1, 1), (1, 1))),\n",
    "            ResNetConvLayer(bottleneck_channels, out_channels, kernel_dims=(1, 1), stride=(1, 1), activation=False),\n",
    "        ]\n",
    "\n",
    "        self.activation = tp.relu\n",
    "\n",
    "    def __call__(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        for layer in self.layer:\n",
    "            x = layer(x)\n",
    "        x = x + identity\n",
    "        x = self.activation(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define resenet stage and encoder for the backbone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetStage(tp.Module):\n",
    "    def __init__(self, num_layers, in_channels, out_channels, bottleneck_channels, stride):\n",
    "        super(ResNetStage, self).__init__()\n",
    "        self.layers = []\n",
    "        for i in range(num_layers):\n",
    "            layer = ResNetBottleNeckLayer(\n",
    "                in_channels if i == 0 else out_channels,\n",
    "                out_channels, bottleneck_channels,\n",
    "                stride if i == 0 else (1, 1)\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetEncoder(tp.Module):\n",
    "    def __init__(self, layers_config):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "        self.stages = []\n",
    "        in_channels = 64\n",
    "        for idx, (num_layers, out_channels, bottleneck_channels, stride) in enumerate(layers_config):\n",
    "            stage = ResNetStage(num_layers, in_channels, out_channels, bottleneck_channels, stride)\n",
    "            self.stages.append(stage)\n",
    "            in_channels = out_channels\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for stage in self.stages:\n",
    "            x = stage(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an embeddings class for input pre-procDefine a max pooling class and embeddings class for input pre-processing before feeding to encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEmbeddings(tp.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetEmbeddings, self).__init__()\n",
    "        self.embedder = ResNetConvLayer(3, 64, kernel_dims=(7, 7), stride=(2, 2), padding=((3, 3), (3, 3)))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.embedder(x)\n",
    "        x = tp.maxpool(x, kernel_dims=(3, 3), stride=(2, 2), padding=((1, 1), (1, 1)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a adaptive average pooling helper function and the resenet backbone model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_avg_pool(x, output_size: tuple[int, int]):\n",
    "    _, _, H_in, W_in = x.shape\n",
    "    H_out, W_out = output_size\n",
    "\n",
    "    # Calculate stride and kernel size\n",
    "    stride_h = H_in // H_out\n",
    "    stride_w = W_in // W_out\n",
    "\n",
    "    kernel_size_h = H_in - (H_out - 1) * stride_h\n",
    "    kernel_size_w = W_in - (W_out - 1) * stride_w\n",
    "\n",
    "    return tp.avgpool(x, kernel_dims=(int(kernel_size_h), int(kernel_size_w)), stride=(int(stride_h), int(stride_w)))\n",
    "\n",
    "class ResNetModel(tp.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.embedder = ResNetEmbeddings()\n",
    "        layers_config = [\n",
    "            (3, 256, 64, (1, 1)),\n",
    "            (4, 512, 128, (2, 2)),\n",
    "            (6, 1024, 256, (2, 2)),\n",
    "            (3, 2048, 512, (2, 2)),\n",
    "        ]\n",
    "        self.encoder = ResNetEncoder(layers_config)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.embedder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = adaptive_avg_pool(x, output_size=(1, 1))\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define resenet classifier head and a wrapper class `TPResNetClassifier` to combine backbone model and classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClassifierHead(tp.Module):\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(ResNetClassifierHead, self).__init__()\n",
    "        setattr(self, \"1\", tp.Linear(in_features, num_classes))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tp.flatten(x, start_dim=1)\n",
    "        x = getattr(self, \"1\")(x)\n",
    "        return x\n",
    "    \n",
    "class ResNetClassifier(tp.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.resnet = ResNetModel()\n",
    "        self.classifier = ResNetClassifierHead(2048, num_classes)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        features = self.resnet(x)\n",
    "        output = self.classifier(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Tripy model\n",
    "tripy_model = ResNetClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights to Tripy Model\n",
    "\n",
    "First we ensure all state dict keys match and then we load the pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all keys match\n",
    "assert (set(list(resnet_pretrained.state_dict().keys())) - set(list(tripy_model.state_dict().keys()))) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_weights_tp(model, state_dict):\n",
    "    \"\"\"\n",
    "    This function loads weights from a state_dict into the custom TPResNet model,\n",
    "    converting them into tp.Parameter before loading.\n",
    "    \"\"\"\n",
    "    model_dict = model.state_dict()  # Get the model's state dict\n",
    "    pretrained_dict = {k: v for k, v in state_dict.items() if k in model_dict}  # Filter weights that exist in model\n",
    "\n",
    "    # Convert each weight to a tp.Parameter and update the model's state dict\n",
    "    for k, v in pretrained_dict.items():\n",
    "        assert k in set(model_dict.keys())\n",
    "        new_v = tp.Parameter(v.contiguous())\n",
    "        # if k.endswith(\"normalization.weight\") or \\\n",
    "        #     k.endswith(\"normalization.bias\") or \\\n",
    "        #     k.endswith(\"normalization.running_mean\") or \\\n",
    "        #     k.endswith(\"normalization.running_var\"):\n",
    "            \n",
    "        #     new_v = tp.reshape(new_v, (1, new_v.shape[0], 1, 1))\n",
    "\n",
    "        model_dict[k] = new_v \n",
    "\n",
    "    # Load the updated state dict\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "    return model\n",
    "\n",
    "pretrained_weights = resnet_pretrained.state_dict()\n",
    "tripy_model = load_pretrained_weights_tp(tripy_model, pretrained_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input tensor\n",
    "input_shape = [1, 3, 224, 224]\n",
    "x = tp.ones(input_shape, dtype=tp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = tp.compile(tripy_model, args=[tp.InputInfo(input_shape, dtype=tp.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_output = compiled_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tripy Demo\n",
    "\n",
    "Now we will test our tripy resnet50 classification model on a few sample images for image classification task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the image for Tripy\n",
    "processed_image = processor(image, return_tensors=\"np\")['pixel_values']\n",
    "tp_image = tp.Tensor(processed_image, dtype=tp.float32, device=tp.device(\"gpu\"))\n",
    "tp_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the image through the model\n",
    "tp_logits = compiled_model(tp_image)\n",
    "tp_logits.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted label\n",
    "tp_predicted_label = torch.argmax(torch.from_dlpack(tp_logits), -1).tolist()[0]\n",
    "print(f\"Predicted Label: {resnet_pretrained.config.id2label[tp_predicted_label]}\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tp_pred(model, image, processor):\n",
    "    processed_image = processor(image, return_tensors=\"np\")['pixel_values']\n",
    "    tp_image = tp.Tensor(processed_image, dtype=tp.float32, device=tp.device(\"gpu\"))\n",
    "    tp_logits = model(tp_image)\n",
    "    return torch.argmax(torch.from_dlpack(tp_logits), -1).tolist()[0]\n",
    "\n",
    "def get_exact_answer(model, image, processor):\n",
    "    inputs = processor(image, return_tensors=\"pt\")['pixel_values'].to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_pretained = model(inputs).logits\n",
    "\n",
    "    return logits_pretained.argmax(-1).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idxs = [1, 44, 10, 28, 105]\n",
    "\n",
    "# Create a figure with a subplot for each image\n",
    "fig, axes = plt.subplots(1, len(idxs), figsize=(15, 3)) \n",
    "\n",
    "# Loop through each index and corresponding subplot\n",
    "for ax, nid in zip(axes, idxs):\n",
    "    image = dataset[nid]['image']\n",
    "    ax.imshow(image)  # Display the image\n",
    "    tp_predicted_label = get_tp_pred(compiled_model, image, processor)\n",
    "    exact_answer = get_exact_answer(resnet_pretrained, image, processor)\n",
    "\n",
    "    pred = resnet_pretrained.config.id2label[tp_predicted_label]\n",
    "    exact = resnet_pretrained.config.id2label[exact_answer]\n",
    "\n",
    "    assert pred == exact, f\"{pred} vs {exact}\"\n",
    "\n",
    "    ax.set_title(pred, fontsize=10, fontweight='bold') \n",
    "    ax.axis('off') \n",
    "    ax.set_xticks([]) \n",
    "    ax.set_yticks([]) \n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=3.0)  # Increase padding between subplots\n",
    "plt.suptitle(\"Visualized Predictions\", fontsize=16, fontweight='bold', y=1.05)  # Title for the entire figure\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
