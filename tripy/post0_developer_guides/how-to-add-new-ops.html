

<!DOCTYPE html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="docsearch:name" content="Tripy" />
    <meta name="docsearch:package_type" content="" />
    <meta name="docsearch:release" content="0.0.1" />
    <meta name="docsearch:version" content="0.0.1" />
    
      <title>Adding New Operators &mdash; Tripy 0.0.1 documentation</title>
    
    <link rel="stylesheet" href="../_static/bootstrap-icons.css" type="text/css" />
          <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=3d3fbe02" />
          <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
          <link id="pygments_dark_css" media="(prefers-color-scheme: dark)" rel="stylesheet" type="text/css" href="../_static/pygments_dark.css?v=b20cc3f5" />
          <link rel="stylesheet" type="text/css" href="../_static/colorsets/sphinx-nefertiti-green.min.css" />
          <link rel="stylesheet" type="text/css" href="../_static/fonts/nunito/stylesheet.css" />
          <link rel="stylesheet" type="text/css" href="../_static/fonts/red-hat-mono/stylesheet.css" />
          <link rel="stylesheet" type="text/css" href="../_static/pygments_dark.css?v=b20cc3f5" />
          <link rel="stylesheet" type="text/css" href="../_static/style.css?v=270043a8" />
        <link rel="index" title="Index" href="../genindex.html" />
        <link rel="search" title="Search" href="../search.html" />
        <link rel="top" title="Tripy 0.0.1 documentation" href="#" />
        <link rel="next" title="Using Python APIs of MLIR Dialects" href="mlir-dialect-python-apis.html" />
        <link rel="prev" title="Design Decisions" href="design-decisions.html" />
    <style>
      :root {
        --nftt-body-font-family: "Nunito", var(--nftt-font-sans-serif) !important;
        --nftt-font-monospace: "Red Hat Mono", var(--nftt-font-family-monospace) !important;
        --nftt-project-name-font: var(--nftt-body-font-family);
        --nftt-documentation-font: var(--nftt-body-font-family);
        --nftt-doc-headers-font: "Georgia", var(--nftt-documentation-font);--nftt-documentation-font-size: 1.0rem;--nftt-monospace-font-size: 0.85rem;}
      h1 *, h2 *, h3 *, h4 *, h5 *, h6 * { font-size: inherit; }
    </style>
  </head>
  <body>
    <header class="navbar navbar-expand-lg navbar-dark nftt-navbar flex-column fixed-top">
      <div class="skip-links container-xxl visually-hidden-focusable overflow-hidden justify-content-start">
        <div class="border-bottom mb-2 pb-2 w-100">
          <a class="d-none d-md-inline-flex p-2 m-1" href="#sidebar-filter">Skip to docs navigation</a>
          <a class="d-inline-flex p-2 m-1" href="#content">Skip to main content</a>
        </div>
      </div>
      <nav class="container-xxl nftt-gutter flex-wrap flex-lg-nowrap" aria-label="Main navigation">
        <div class="nftt-navbar-toggler">
          <button class="navbar-toggler p-2" type="button" data-bs-toggle="offcanvas" data-bs-target="#sidebar" aria-controls="sidebar" aria-label="Toggle documentation navigation">
            <i class="bi bi-list"></i>
          </button>
        </div>
          <a href="../index.html"
              
              class="navbar-brand p-0 me-0 md-lg-2"
          ><span class="brand-text">Tripy</span></a>
        
        <div class="d-flex d-lg-none">
          <button class="navbar-toggler p-2" type="button" data-bs-toggle="offcanvas" data-bs-target="#nfttSearch" aria-controls="nfttSearch" aria-label="Search">
            <i class="bi bi-search"></i>
          </button>
          <button class="navbar-toggler p-2" type="button" data-bs-toggle="offcanvas" data-bs-target="#nfttNavbar" aria-controls="nfttNavbar" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
        </div>
        
<div class="offcanvas-lg offcanvas-end flex-grow-1" tabindex="-1" id="nfttSearch" aria-labelledby="nfttSearchOffcanvasLabel" data-bs-scroll="true">
  <div class="offcanvas-header px-4 pb-0">
    <h5 class="offcanvas-title fw-bold" id="nfttSearchOffcanvasLabel">Search the documentation</h5>
    <button type="button" class="btn-close" data-bs-dismiss="offcanvas" aria-label="Close" data-bs-target="#nfttSearch"></button>
  </div>
  <div class="offcanvas-body p-4 pt-0 p-lg-0 px-lg-3">
    <hr class="d-lg-none text-white-50">
    <ul class="navbar-nav flex-row align-items-center flex-wrap ms-md-auto">
      <li class="nav-item col-12 col-lg-auto">
        <form id="nftt-search-form" action="../search.html" method="get">
          <div class="input-group">
            <input type="text" name="q" class="form-control" placeholder="Search docs" aria-label="Search" aria-describedby="button-search">
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
            <button class="btn btn-primary" type="submit" id="button-search" aria-label="Search"><i class="bi bi-search"></i></button>
          </div>
        </form>
      </li>
    </ul>
  </div>
</div>

        <div class="offcanvas-lg offcanvas-end" tabindex="-1" id="nfttNavbar" aria-labelledby="nfttNavbarOffcanvasLabel" data-bs-scroll="true">
          <div class="offcanvas-header px-4 pb-0">
            <div class="offcanvas-title text-white fw-bold" id="nfttNavbarOffcanvasLabel"><span class="brand-text">Nefertiti for Sphinx</span></div>
            <button type="button" class="btn-close btn-close-white" data-bs-dismiss="offcanvas" aria-label="Close" data-bs-target="#nfttNavbar"></button>
          </div>
          <div class="offcanvas-body p-4 pt-0 p-lg-0">
            <hr class="d-lg-none text-white-50">
            <ul class="navbar-nav flex-row align-items-center flex-wrap ms-md-auto">
              
              <li class="nav-item col-12 col-lg-auto">
                <a class="nav-link py-2 py-lg-0 px-0 px-lg-2" href="https://github.com/NVIDIA/TensorRT-Incubator" target="_blank" rel="noopener">
                  <div class="d-flex align-items-center">
                    <div class="me-2">
                      <i class="bi bi-git size-24"></i>
                    </div>
                    <div class="repo d-flex flex-column align-items-center" data-snftt-repo-url="https://github.com/NVIDIA/TensorRT-Incubator">
                      Tripy
                      <div class="d-flex justify-content-center" data-snftt-repo-metrics>
                        <span class="pe-2 d-flex justify-content-center align-items-center">
                          <i class="bi bi-tag size-14"></i>
                          <span class="repo-metric" data-snftt-repo-tag></span>
                        </span>
                        <span class="pe-2 d-flex justify-content-center align-items-center">
                          <i class="bi bi-star size-14"></i>
                          <span class="repo-metric" data-snftt-repo-stars></span>
                        </span>
                        <span class="d-flex justify-content-center align-items-center">
                          <i class="bi bi-diagram-2 size-14"></i>
                          <span class="repo-metric" data-snftt-repo-forks></span>
                        </span>
                      </div>
                    </div>
                  </div>
                </a>
              </li>
              <li class="nav-item col-12 col-lg-auto h-100" aria-hidden="true">
                <div class="vr d-none d-lg-flex h-100 mx-lg-2 text-white"></div>
                <hr class="d-lg-none text-white-50">
              </li>
              
              <!-- version_dropdown.html -->

              
              <!-- colorscheme_dropdown.html -->
<li class="nav-item dropdown">
  <a class="nav-link d-flex py-2 px-0 px-lg-2 dropdown-toggle align-items-center" id="snftt-luz" href="#" data-bs-toggle="dropdown" data-bs-display="static" aria-expanded="false" aria-label="Toggle light/dark">
    <i class="bi bi-circle-half" data-snftt-luz-icon-active></i>
    <span id="snftt-luz-text" class="d-lg-none small ms-2">Toggle light/dark</span>
  </a>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="snftt-luz-text">
    <li>
      <h6 class="dropdown-header">Light/dark</h6>
    </li>
    <li>
      <a class="dropdown-item d-flex align-items-center" data-snftt-luz="light" href="#" aria-pressed="false">
        <span class="small">
          <i class="bi bi-sun" data-snftt-luz-icon="light"></i>
        </span>
        <span class="small ms-3">Light</span>
        <i class="bi bi-check ms-auto"></i>
      </a>
    </li>
    <li>
      <a class="dropdown-item d-flex align-items-center" data-snftt-luz="dark" href="#" aria-pressed="false">
        <span class="small">
          <i class="bi bi-moon-stars" data-snftt-luz-icon="dark"></i>
        </span>
        <span class="small ms-3">Dark</span>
        <i class="bi bi-check ms-auto"></i>
      </a>
    </li>
    <li>
      <a class="dropdown-item current d-flex align-items-center" data-snftt-luz="default" href="#" aria-pressed="false">
        <span class="small">
          <i class="bi bi-circle-half" data-snftt-luz-icon="default"></i>
        </span>
        <span class="small ms-3">Default</span>
        <i class="bi bi-check ms-auto"></i>
      </a>
    </li>
  </ul>
</li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <div class="container-xxl nftt-gutter nftt-layout">
      <aside class="nftt-sidebar">
        <div class="title d-none d-md-block">
          <i class="bi bi-book"></i>&nbsp;&nbsp;<span>Table of contents</span>
        </div>
        <div id="sidebar" tabindex="-1" class="offcanvas-lg offcanvas-start" aria-labelledby="nfttSidebarOffcanvasLabel">
            <!-- danirus sidebartemplate: "globaltoc.html" --><div class="offcanvas-header border-bottom">
  <h5 class="offcanvas-title" id="nfttSidebarOffcanvasLabel">
    Table of contents
  </h5>
  <button type="button" class="btn-close" data-bs-dismiss="offcanvas" aria-label="Close" data-bs-target="#sidebar"></button>
</div>

<div class="offcanvas-body">
  <nav class="toc" aria-label="Main menu">
    <div class="mb-3 p-1 pt-3 pb-4 border-bottom">
      <input id="sidebar-filter" type="text" name="filter" class="form-control form-control-sm" placeholder="filter" aria-label="filter">
    </div>
    <p class="caption" role="heading"><span class="caption-text">User Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pre0_user_guides/introduction-to-tripy.html">An Introduction To Tripy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pre0_user_guides/quantization.html">Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../compiler/index.html">Compiler</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../compiler/arg_info.html">ArgInfo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compiler/executable.html">Executable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../compiler/input_info.html">InputInfo</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../config.html">config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datatype.html">dtype</a></li>
<li class="toctree-l1"><a class="reference internal" href="../device.html">device</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exception/index.html">Exception</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../exception/tripy_exception.html">TripyException</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../logger.html">logger</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/index.html">Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../modules/conv.html">Conv</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/conv_transpose.html">ConvTranspose</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/embedding.html">Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/group_norm.html">GroupNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/layer_norm.html">LayerNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/linear.html">Linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/parameter.html">Parameter</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../shape.html">Shape</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor/index.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor_operations/index.html">Tensor Operations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/abs.html">abs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/all.html">all</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/allclose.html">allclose</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/any.html">any</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/arange.html">arange</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/argmax.html">argmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/argmin.html">argmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/cast.html">cast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/concatenate.html">concatenate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/copy.html">copy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/cos.html">cos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/dequantize.html">dequantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/exp.html">exp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/expand.html">expand</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/flip.html">flip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/full.html">full</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/full_like.html">full_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/gather.html">gather</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/gelu.html">gelu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/iota.html">iota</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/iota_like.html">iota_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/log.html">log</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/masked_fill.html">masked_fill</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/max.html">max</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/maximum.html">maximum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/mean.html">mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/minimum.html">minimum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/ones.html">ones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/ones_like.html">ones_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/permute.html">permute</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/plugin.html">plugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/prod.html">prod</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/quantize.html">quantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/relu.html">relu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/reshape.html">reshape</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/rsqrt.html">rsqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/sigmoid.html">sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/silu.html">silu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/sin.html">sin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/softmax.html">softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/split.html">split</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/sqrt.html">sqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/squeeze.html">squeeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/sum.html">sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/tanh.html">tanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/transpose.html">transpose</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/tril.html">tril</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/triu.html">triu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/unsqueeze.html">unsqueeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/var.html">var</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/where.html">where</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/zeros.html">zeros</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_operations/zeros_like.html">zeros_like</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guides</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugging.html">Debugging MLIR-TensorRT backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="design-decisions.html">Design Decisions</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Adding New Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlir-dialect-python-apis.html">Using Python APIs of MLIR Dialects</a></li>
</ul>

  </nav>
  <template data-toggle-item-template>
    <button class="btn btn-sm btn-link toctree-expand" type="button">
      <i class="bi bi-caret-right"></i>
      <span class="visually-hidden">Toggle menu contents</span>
    </button>
  </template>
</div>
        </div>
      </aside>
      <main class="nftt-main">
        <article id="content" class="nftt-content" role="main">
    <section id="adding-new-operators">
<h1><a class="toc-backref" href="#id2" role="doc-backlink">Adding New Operators</a><a class="headerlink" href="#adding-new-operators" title="Link to this heading">¶</a></h1>
<p><em>You may find it helpful to read the <a class="reference internal" href="architecture.html"><span class="std std-doc">architecture</span></a> documentation</em>
<em>before you start reading this guide.</em></p>
<p>Adding new operators to Tripy typically involves making changes in the frontend as well
as in the <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code>. In some cases, the frontend operator can be expressed in terms of existing
<code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> operators, in which case you only need to make changes in the frontend.</p>
<p>Let’s take a look at an example of how you might add an <code class="docutils literal notranslate"><span class="pre">Iota</span></code> operator to Tripy.
So that it doesn’t clash with Tripy’s actual <code class="docutils literal notranslate"><span class="pre">Iota</span></code> implementation, we’ll call it
<code class="docutils literal notranslate"><span class="pre">Theta</span></code> instead.</p>
<nav class="contents" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#adding-new-operators" id="id2">Adding New Operators</a></p>
<ul>
<li><p><a class="reference internal" href="#implementation" id="id3">Implementation</a></p>
<ul>
<li><p><a class="reference internal" href="#flatir-operator" id="id4"><code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> Operator</a></p></li>
<li><p><a class="reference internal" href="#exposing-the-operator" id="id5">Exposing The Operator</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#trace-operator-and-the-public-api" id="id6"><code class="docutils literal notranslate"><span class="pre">Trace</span></code> Operator And The Public API</a></p>
<ul>
<li><p><a class="reference internal" href="#trace-operator" id="id7"><code class="docutils literal notranslate"><span class="pre">Trace</span></code> Operator</a></p></li>
<li><p><a class="reference internal" href="#public-api" id="id8">Public API</a></p></li>
<li><p><a class="reference internal" href="#id1" id="id9">Exposing The Operator</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#testing" id="id10">Testing</a></p>
<ul>
<li><p><a class="reference internal" href="#testing-the-flatir-operator" id="id11">Testing The <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> Operator</a></p></li>
<li><p><a class="reference internal" href="#testing-the-trace-operator-and-public-api" id="id12">Testing The Trace Operator And Public API</a></p></li>
<li><p><a class="reference internal" href="#integration-tests" id="id13">Integration Tests</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#done" id="id14">Done!</a></p></li>
</ul>
</li>
</ul>
</nav>
<!-- Use the TEST: USE_PYTEST marker since we'll be defining unit tests as part of the guide.
    With this marker, those tests can actually be run under pytest. -->
<section id="implementation">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Implementation</a><a class="headerlink" href="#implementation" title="Link to this heading">¶</a></h2>
<section id="flatir-operator">
<h3><a class="toc-backref" href="#id4" role="doc-backlink"><code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> Operator</a><a class="headerlink" href="#flatir-operator" title="Link to this heading">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> operator is usually the most challenging aspect of implementing operators
in Tripy. The good news is that you might not even need to do this if the low-level operators
you need already exist in the <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code>. And if you do, then it’ll only get easier after this!</p>
<p>We’ll start by adding a new file under <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/flat_ir/ops/"><code class="docutils literal notranslate"><span class="pre">tripy/flat_ir/ops</span></code></a> called
<code class="docutils literal notranslate"><span class="pre">theta.py</span></code>; see the inline comments for explanations of what’s happening:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="linenos"> 2</span>
<span class="linenos"> 3</span><span class="kn">from</span> <span class="nn">mlir_tensorrt.compiler</span> <span class="kn">import</span> <span class="n">ir</span>
<span class="linenos"> 4</span><span class="kn">from</span> <span class="nn">mlir_tensorrt.compiler.dialects</span> <span class="kn">import</span> <span class="n">stablehlo</span>
<span class="linenos"> 5</span>
<span class="linenos"> 6</span><span class="kn">from</span> <span class="nn">tripy.flat_ir.ops.base</span> <span class="kn">import</span> <span class="n">BaseFlatIROp</span>
<span class="linenos"> 7</span>
<span class="linenos"> 8</span>
<span class="linenos"> 9</span><span class="c1"># Every `FlatIR` operator is implemented as a `dataclass` so that the base</span>
<span class="linenos">10</span><span class="c1"># class can automatically implement several methods by inspecting the child</span>
<span class="linenos">11</span><span class="c1"># class fields at runtime. The `repr=False` is important because the default</span>
<span class="linenos">12</span><span class="c1"># `__repr__` method generated by `dataclass` will be extremely verbose and</span>
<span class="linenos">13</span><span class="c1"># makes interactive debugging more difficult.</span>
<span class="linenos">14</span><span class="nd">@dataclass</span><span class="p">(</span><span class="nb">repr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="linenos">15</span><span class="k">class</span> <span class="nc">ThetaOp</span><span class="p">(</span><span class="n">BaseFlatIROp</span><span class="p">):</span>
<span class="linenos">16</span>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span>
<span class="linenos">17</span>
<span class="linenos">18</span>    <span class="c1"># `to_mlir()` is the trickiest bit. As the name implies, the method is meant to lower the</span>
<span class="linenos">19</span>    <span class="c1"># `FlatIR` operator into MLIR. To figure out which MLIR operators to use, refer to</span>
<span class="linenos">20</span>    <span class="c1"># the &#39;MLIR Python API Guide&#39; (linked below).</span>
<span class="linenos">21</span>    <span class="k">def</span> <span class="nf">to_mlir</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operands</span><span class="p">):</span>
<span class="linenos">22</span>        <span class="n">out_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to_mlir</span><span class="p">()</span>
<span class="linenos">23</span>        <span class="n">theta_dim</span> <span class="o">=</span> <span class="n">ir</span><span class="o">.</span><span class="n">IntegerAttr</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="n">ir</span><span class="o">.</span><span class="n">IntegerType</span><span class="o">.</span><span class="n">get_signless</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
<span class="linenos">24</span>        <span class="n">output</span> <span class="o">=</span> <span class="n">stablehlo</span><span class="o">.</span><span class="n">DynamicIotaOp</span><span class="p">(</span><span class="n">result</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="n">operands</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">iota_dimension</span><span class="o">=</span><span class="n">theta_dim</span><span class="p">)</span>
<span class="linenos">25</span>        <span class="k">return</span> <span class="p">[</span><span class="n">output</span><span class="p">]</span>
</pre></div>
</div>
<p>Links:</p>
<ul class="simple">
<li><p><a class="reference internal" href="mlir-dialect-python-apis.html"><span class="std std-doc">MLIR Python API Guide</span></a></p></li>
</ul>
</section>
<section id="exposing-the-operator">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">Exposing The Operator</a><a class="headerlink" href="#exposing-the-operator" title="Link to this heading">¶</a></h3>
<p>One of the principles we follow when writing submodules is that other submodules should
not need to reach into the internals of a submodule to retrieve something they need.</p>
<p>For example, a class which needs to import <code class="docutils literal notranslate"><span class="pre">ThetaOp</span></code> does not need to know where exactly
within the <code class="docutils literal notranslate"><span class="pre">flat_ir.ops</span></code> module the <code class="docutils literal notranslate"><span class="pre">ThetaOp</span></code> lives - it should be able to just import it
from the submodule.</p>
<p>To make this possible, we need to import the <code class="docutils literal notranslate"><span class="pre">ThetaOp</span></code> into the <code class="docutils literal notranslate"><span class="pre">flat_ir.ops</span></code> submodule.
We can do so by adding the following line into
<a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/flat_ir/ops/__init__.py"><code class="docutils literal notranslate"><span class="pre">tripy/flat_ir/ops/__init__.py</span></code></a>:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="kn">from</span> <span class="nn">tripy.flat_ir.ops.theta</span> <span class="kn">import</span> <span class="n">ThetaOp</span>
</pre></div>
</div>
</section>
</section>
<section id="trace-operator-and-the-public-api">
<h2><a class="toc-backref" href="#id6" role="doc-backlink"><code class="docutils literal notranslate"><span class="pre">Trace</span></code> Operator And The Public API</a><a class="headerlink" href="#trace-operator-and-the-public-api" title="Link to this heading">¶</a></h2>
<p>Now that we have a <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> operator, we can implement a <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operator that will use it
along with a public API function. Let’s create a new file under
<a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/frontend/trace/ops/"><code class="docutils literal notranslate"><span class="pre">tripy/frontend/trace/ops</span></code></a> called <code class="docutils literal notranslate"><span class="pre">theta.py</span></code>.</p>
<section id="trace-operator">
<h3><a class="toc-backref" href="#id7" role="doc-backlink"><code class="docutils literal notranslate"><span class="pre">Trace</span></code> Operator</a><a class="headerlink" href="#trace-operator" title="Link to this heading">¶</a></h3>
<p>First, we’ll implement the <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operator itself:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="linenos"> 2</span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>
<span class="linenos"> 3</span>
<span class="linenos"> 4</span><span class="kn">from</span> <span class="nn">tripy</span> <span class="kn">import</span> <span class="n">utils</span>
<span class="linenos"> 5</span><span class="kn">from</span> <span class="nn">tripy.common</span> <span class="kn">import</span> <span class="n">datatype</span><span class="p">,</span> <span class="n">device</span>
<span class="linenos"> 6</span><span class="kn">from</span> <span class="nn">tripy.common.exception</span> <span class="kn">import</span> <span class="n">raise_error</span>
<span class="linenos"> 7</span><span class="kn">from</span> <span class="nn">tripy.frontend.trace.ops.base</span> <span class="kn">import</span> <span class="n">BaseTraceOp</span>
<span class="linenos"> 8</span><span class="kn">import</span> <span class="nn">tripy.frontend.trace.ops.utils</span> <span class="k">as</span> <span class="nn">op_utils</span>
<span class="linenos"> 9</span>
<span class="linenos">10</span>
<span class="linenos">11</span><span class="c1"># Just like with `FlatIR` operators, all `Trace` operators are implemented as `dataclass`es.</span>
<span class="linenos">12</span><span class="c1"># As before, we want `repr=False` here.</span>
<span class="linenos">13</span><span class="nd">@dataclass</span><span class="p">(</span><span class="nb">repr</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="linenos">14</span><span class="k">class</span> <span class="nc">Theta</span><span class="p">(</span><span class="n">BaseTraceOp</span><span class="p">):</span>
<span class="linenos">15</span>    <span class="c1"># Notice that we do *not* need to define a constructor and can rely on the default</span>
<span class="linenos">16</span>    <span class="c1"># implementation provided by `dataclass`.</span>
<span class="linenos">17</span>    <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span>
<span class="linenos">18</span>    <span class="n">dtype</span><span class="p">:</span> <span class="n">datatype</span><span class="o">.</span><span class="n">dtype</span>
<span class="linenos">19</span>
<span class="linenos">20</span>    <span class="c1"># The `infer_shape_output_idxs` method should indicate which outputs of this operator represent shapes.</span>
<span class="linenos">21</span>    <span class="c1"># The corresponding outputs will be wrapped as `tripy.Shape` objects instead of regular `tripy.Tensor`s.</span>
<span class="linenos">22</span>    <span class="c1"># Our `Theta` operation should never return shapes, so we can use the corresponding preexisting policy.</span>
<span class="linenos">23</span>    <span class="n">infer_shape_output_idxs</span> <span class="o">=</span> <span class="n">op_utils</span><span class="o">.</span><span class="n">ShapeOutputIdxPolicies</span><span class="o">.</span><span class="n">never_return_shape</span>
<span class="linenos">24</span>
<span class="linenos">25</span>    <span class="c1"># *Optional* `infer_dtypes()` populates the data types of the</span>
<span class="linenos">26</span>    <span class="c1"># output `TraceTensor`s. The default implementation copies the input</span>
<span class="linenos">27</span>    <span class="c1"># data types if they are all the same, so you may not need to implement this.</span>
<span class="linenos">28</span>    <span class="k">def</span> <span class="nf">infer_dtypes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">29</span>        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
<span class="linenos">30</span>
<span class="linenos">31</span>    <span class="c1"># *Optional* `infer_devices()` populates the devices of the</span>
<span class="linenos">32</span>    <span class="c1"># output `TraceTensor`s. The default implementation copies the input</span>
<span class="linenos">33</span>    <span class="c1"># devices if they are all the same, so you may not need to implement this either.</span>
<span class="linenos">34</span>    <span class="k">def</span> <span class="nf">infer_devices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">35</span>        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">(</span><span class="s2">&quot;gpu&quot;</span><span class="p">)</span>
<span class="linenos">36</span>
<span class="linenos">37</span>    <span class="c1"># `infer_rank()` populates the rank of the output `TraceTensor`s.</span>
<span class="linenos">38</span>    <span class="c1"># For most operators, the output rank will depend on the rank of `self.inputs`.</span>
<span class="linenos">39</span>    <span class="c1"># In our case, since `Theta` generates a tensor, there is no input tensor.</span>
<span class="linenos">40</span>    <span class="k">def</span> <span class="nf">infer_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">41</span>        <span class="kn">from</span> <span class="nn">tripy.backend.mlir.utils</span> <span class="kn">import</span> <span class="n">ShapeContext</span>
<span class="linenos">42</span>
<span class="linenos">43</span>        <span class="c1"># `self.inputs[0]` indicates the desired shape of the output.</span>
<span class="linenos">44</span>        <span class="c1"># Here, we compute the number of elements in the shape tensor, which determines the rank of the output.</span>
<span class="linenos">45</span>        <span class="n">out_shape</span> <span class="o">=</span> <span class="n">ShapeContext</span><span class="p">()</span><span class="o">.</span><span class="n">get_shape_of_dynamic_trace_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="linenos">46</span>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Expected rank of shape tensor to be 1, got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">out_shape</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="linenos">47</span>        <span class="k">assert</span> <span class="p">(</span>
<span class="linenos">48</span>            <span class="n">out_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">0</span>
<span class="linenos">49</span>        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Incorrect shape of shape tensor, expected shape to be positive, got </span><span class="si">{</span><span class="n">out_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="linenos">50</span>        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">out_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos">51</span>
<span class="linenos">52</span>    <span class="c1"># `to_flat_ir()` translates the `Trace` operator to a subgraph of</span>
<span class="linenos">53</span>    <span class="c1"># one or more `FlatIR` operators. In our case, it&#39;s just a 1:1</span>
<span class="linenos">54</span>    <span class="c1"># mapping to the `ThetaOp` we created earlier.</span>
<span class="linenos">55</span>    <span class="k">def</span> <span class="nf">to_flat_ir</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
<span class="linenos">56</span>        <span class="c1"># Note that we import the `FlatIR` operator within the function</span>
<span class="linenos">57</span>        <span class="c1"># call - this is to avoid circular dependencies.</span>
<span class="linenos">58</span>        <span class="kn">from</span> <span class="nn">tripy.flat_ir.ops</span> <span class="kn">import</span> <span class="n">ThetaOp</span>
<span class="linenos">59</span>        <span class="kn">import</span> <span class="nn">tripy.frontend.trace.ops.utils</span> <span class="k">as</span> <span class="nn">op_utils</span>
<span class="linenos">60</span>
<span class="linenos">61</span>        <span class="c1"># This code may look a bit confusing; for more details, look at the</span>
<span class="linenos">62</span>        <span class="c1"># &#39;FlatIR section in the architecture document&#39; (linked below).</span>
<span class="linenos">63</span>        <span class="n">ThetaOp</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>
</pre></div>
</div>
<p>Links:</p>
<ul class="simple">
<li><p><a class="reference internal" href="architecture.html#lowering-to-flatir"><span class="std std-ref">FlatIR section in the architecture document</span></a></p></li>
</ul>
</section>
<section id="public-api">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Public API</a><a class="headerlink" href="#public-api" title="Link to this heading">¶</a></h3>
<p>Next, we can define the public interface. Since our public interface maps 1:1 with the <code class="docutils literal notranslate"><span class="pre">Trace</span></code>
operator we just implemented and does not require weights, we’ll add it in the same file.</p>
<p>If our API required a composition of multiple <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operators, then we would instead implement
it under <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/frontend/ops"><code class="docutils literal notranslate"><span class="pre">frontend/ops/</span></code></a>.</p>
<p>If it required weights (i.e. inputs that are expected to always be constant), then we would implement
it as a <code class="docutils literal notranslate"><span class="pre">tripy.Module</span></code> under <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/frontend/module"><code class="docutils literal notranslate"><span class="pre">frontend/module</span></code></a>.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">from</span> <span class="nn">tripy</span> <span class="kn">import</span> <span class="n">export</span>
<span class="linenos"> 2</span><span class="kn">import</span> <span class="nn">tripy.frontend.utils</span> <span class="k">as</span> <span class="nn">frontend_utils</span>
<span class="linenos"> 3</span>
<span class="linenos"> 4</span><span class="c1"># We can use the `export.public_api()` decorator to automatically export this function into the</span>
<span class="linenos"> 5</span><span class="c1"># top-level module. This means it will be accessible as `tripy.theta`.</span>
<span class="linenos"> 6</span><span class="c1">#</span>
<span class="linenos"> 7</span><span class="c1"># This decorator also controls how the API is exposed in the documentation - the `document_under`</span>
<span class="linenos"> 8</span><span class="c1"># option determines where in the documentation hierarchy this API will show up.</span>
<span class="linenos"> 9</span><span class="c1">#</span>
<span class="linenos">10</span><span class="c1"># If we needed to provide any special autodoc options, we could use the `autodoc_options` parameter.</span>
<span class="linenos">11</span><span class="nd">@export</span><span class="o">.</span><span class="n">public_api</span><span class="p">(</span><span class="n">document_under</span><span class="o">=</span><span class="s2">&quot;tensor_operations&quot;</span><span class="p">)</span>
<span class="linenos">12</span>
<span class="linenos">13</span><span class="c1"># The `convert_inputs_to_tensors` decorator converts function arguments to Tensors.</span>
<span class="linenos">14</span><span class="c1"># This is what makes it possible for the user to use Python numbers in Tripy functions (e.g. `tensor + 1`)</span>
<span class="linenos">15</span><span class="c1"># In this case, we want `shape` to turn into a `tripy.Shape` instead of a regular `Tensor`.</span>
<span class="linenos">16</span><span class="nd">@frontend_utils</span><span class="o">.</span><span class="n">convert_inputs_to_tensors</span><span class="p">(</span><span class="n">shape_argument</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;shape&quot;</span><span class="p">],</span> <span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;dim&quot;</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">])</span>
<span class="linenos">17</span><span class="k">def</span> <span class="nf">theta</span><span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">datatype</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">datatype</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;tripy.Tensor&quot;</span><span class="p">:</span>
<span class="linenos">18</span>    <span class="c1"># For any public facing interfaces, we have documentation requirements which you can read</span>
<span class="linenos">19</span>    <span class="c1"># about in the &#39;Docs README&#39; (linked below). The docstring we&#39;ve implemented here</span>
<span class="linenos">20</span>    <span class="c1"># adheres to all of these requirements. Non-compliant docstrings will, in most cases,</span>
<span class="linenos">21</span>    <span class="c1"># cause test failures; however, you should still manually ensure you&#39;re writing high-quality</span>
<span class="linenos">22</span>    <span class="c1"># docstrings.</span>
<span class="linenos">23</span>    <span class="c1">#</span>
<span class="linenos">24</span>    <span class="c1"># The examples in docstrings are run as part of our tests, so you should also add</span>
<span class="linenos">25</span>    <span class="c1"># assertions to make sure things are functionally correct. In this case, we check</span>
<span class="linenos">26</span>    <span class="c1"># that the `output` we create in the code example is what we expect.</span>
<span class="linenos">27</span><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos">28</span><span class="sd">    Fills an output tensor with consecutive values starting from zero along the given dimension.</span>
<span class="linenos">29</span>
<span class="linenos">30</span><span class="sd">    Args:</span>
<span class="linenos">31</span><span class="sd">        shape: The desired shape.</span>
<span class="linenos">32</span><span class="sd">        dim: Dimension along which to perform the theta operation.</span>
<span class="linenos">33</span><span class="sd">            This cannot exceed the rank of the specified shape.</span>
<span class="linenos">34</span><span class="sd">        dtype: The desired data type.</span>
<span class="linenos">35</span>
<span class="linenos">36</span><span class="sd">    Returns:</span>
<span class="linenos">37</span><span class="sd">        A tensor of shape ``shape`` and data type ``dtype``.</span>
<span class="linenos">38</span>
<span class="linenos">39</span><span class="sd">    .. code-block:: python</span>
<span class="linenos">40</span><span class="sd">        :linenos:</span>
<span class="linenos">41</span><span class="sd">        :caption: Example</span>
<span class="linenos">42</span>
<span class="linenos">43</span><span class="sd">        output = tp.theta([3])</span>
<span class="linenos">44</span>
<span class="linenos">45</span><span class="sd">        assert np.array_equal(cp.from_dlpack(output).get(), np.arange(0, 3, dtype=np.float32))</span>
<span class="linenos">46</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos">47</span>
<span class="linenos">48</span>    <span class="c1"># Next we build the trace operator. The `build()` function is also responsible for constructing</span>
<span class="linenos">49</span>    <span class="c1"># the output frontend Tensors. All of the arguments that follow the inputs</span>
<span class="linenos">50</span>    <span class="c1"># are forwarded directly to the constructor of the `Trace` operator.</span>
<span class="linenos">51</span>    <span class="k">return</span> <span class="n">Theta</span><span class="o">.</span><span class="n">build</span><span class="p">([</span><span class="n">shape</span><span class="p">],</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
<span class="linenos">52</span>
</pre></div>
</div>
<p>Links:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//docs/README.md">Docs README</a></p></li>
</ul>
</section>
<section id="id1">
<h3><a class="toc-backref" href="#id9" role="doc-backlink">Exposing The Operator</a><a class="headerlink" href="#id1" title="Link to this heading">¶</a></h3>
<p>Similarly to the <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> operator, we need to import <code class="docutils literal notranslate"><span class="pre">Theta</span></code> into the
<code class="docutils literal notranslate"><span class="pre">frontend.trace.ops</span></code> submodule. We can do so by adding the following line into
<a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/frontend/trace/ops/__init__.py"><code class="docutils literal notranslate"><span class="pre">tripy/frontend/trace/ops/__init__.py</span></code></a>:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="kn">from</span> <span class="nn">tripy.frontend.trace.ops.theta</span> <span class="kn">import</span> <span class="n">Theta</span><span class="p">,</span> <span class="n">theta</span>
</pre></div>
</div>
</section>
</section>
<section id="testing">
<h2><a class="toc-backref" href="#id10" role="doc-backlink">Testing</a><a class="headerlink" href="#testing" title="Link to this heading">¶</a></h2>
<p>Now that we’ve implemented our operator, let’s write tests for it. The structure of the
<a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tests/"><code class="docutils literal notranslate"><span class="pre">tests/</span></code></a> directory mirrors that of the <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/"><code class="docutils literal notranslate"><span class="pre">tripy/</span></code></a> directory
(you can read more about that <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tests/README.md">here</a>). We need to test both the <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code>
and <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operators.</p>
<section id="testing-the-flatir-operator">
<h3><a class="toc-backref" href="#id11" role="doc-backlink">Testing The <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> Operator</a><a class="headerlink" href="#testing-the-flatir-operator" title="Link to this heading">¶</a></h3>
<p>When testing our <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> operator, we essentially need to test two things:</p>
<ol class="arabic simple">
<li><p>Is the string reprensetation of the operator correct? We need to make sure it is since this
is what will appear in the <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> dumps.</p></li>
<li><p>Is the translation to MLIR correct?</p></li>
</ol>
<p>Since we implemented the <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> operator in <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/flat_ir/ops/"><code class="docutils literal notranslate"><span class="pre">tripy/flat_ir/ops</span></code></a>, we’ll
add the corresponding test under <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tests/flat_ir/ops/"><code class="docutils literal notranslate"><span class="pre">tests/flat_ir/ops</span></code></a>. Create a new file
there called <code class="docutils literal notranslate"><span class="pre">test_theta.py</span></code>.</p>
<p>We’ll start by defining a pytest fixture that will generate a <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> containing a <code class="docutils literal notranslate"><span class="pre">ThetaOp</span></code> for us.
To do so, we can simply use the public API, generate a <code class="docutils literal notranslate"><span class="pre">Trace</span></code>, and convert to <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code>:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">import</span> <span class="nn">pytest</span>
<span class="linenos"> 2</span><span class="kn">import</span> <span class="nn">re</span>
<span class="linenos"> 3</span>
<span class="linenos"> 4</span><span class="kn">import</span> <span class="nn">tripy</span> <span class="k">as</span> <span class="nn">tp</span>
<span class="linenos"> 5</span><span class="kn">from</span> <span class="nn">tests</span> <span class="kn">import</span> <span class="n">helper</span>
<span class="linenos"> 6</span><span class="kn">from</span> <span class="nn">tripy.frontend.trace</span> <span class="kn">import</span> <span class="n">Trace</span>
<span class="linenos"> 7</span><span class="kn">from</span> <span class="nn">tripy.flat_ir.ops</span> <span class="kn">import</span> <span class="n">IotaOp</span>
<span class="linenos"> 8</span>
<span class="linenos"> 9</span>
<span class="linenos">10</span><span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="linenos">11</span><span class="k">def</span> <span class="nf">flat_ir</span><span class="p">():</span>
<span class="linenos">12</span>    <span class="n">out</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">theta</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="linenos">13</span>    <span class="n">out</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;out&quot;</span>
<span class="linenos">14</span>
<span class="linenos">15</span>    <span class="n">trace</span> <span class="o">=</span> <span class="n">Trace</span><span class="p">([</span><span class="n">out</span><span class="p">])</span>
<span class="linenos">16</span>    <span class="k">yield</span> <span class="n">trace</span><span class="o">.</span><span class="n">to_flat_ir</span><span class="p">()</span>
</pre></div>
</div>
<p>Now we can create a test class with our two tests:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="k">class</span> <span class="nc">TestThetaOp</span><span class="p">:</span>
<span class="linenos"> 2</span>    <span class="c1"># This tests the string representation of our `FlatIR` operator.</span>
<span class="linenos"> 3</span>    <span class="c1"># This may be hard to predict, so we suggest that you first `print(str(Theta))`,</span>
<span class="linenos"> 4</span>    <span class="c1"># check if it looks correct, and then add the corresponding string to the test.</span>
<span class="linenos"> 5</span>    <span class="k">def</span> <span class="nf">test_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flat_ir</span><span class="p">):</span>
<span class="linenos"> 6</span>        <span class="n">Theta</span> <span class="o">=</span> <span class="n">flat_ir</span><span class="o">.</span><span class="n">ops</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="linenos"> 7</span>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">Theta</span><span class="p">,</span> <span class="n">ThetaOp</span><span class="p">)</span>
<span class="linenos"> 8</span>        <span class="k">assert</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span>
<span class="linenos"> 9</span>            <span class="sa">r</span><span class="s2">&quot;out: \[rank=\(2\), dtype=\(float32\), loc=\(gpu:0\)\] = ThetaOp\(t[0-9]+, dim=0\)&quot;</span><span class="p">,</span>
<span class="linenos">10</span>            <span class="nb">str</span><span class="p">(</span><span class="n">Theta</span><span class="p">),</span>
<span class="linenos">11</span>        <span class="p">)</span>
<span class="linenos">12</span>
<span class="linenos">13</span>
<span class="linenos">14</span>    <span class="c1"># This tests conversion to MLIR by checking the generated MLIR module code. Once again,</span>
<span class="linenos">15</span>    <span class="c1"># this is difficult to predict ahead of time, so you should print the MLIR module once,</span>
<span class="linenos">16</span>    <span class="c1"># check if it looks correct, and then update the test accordingly.</span>
<span class="linenos">17</span>    <span class="k">def</span> <span class="nf">test_mlir</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flat_ir</span><span class="p">):</span>
<span class="linenos">18</span>        <span class="n">helper</span><span class="o">.</span><span class="n">check_mlir</span><span class="p">(</span>
<span class="linenos">19</span>            <span class="n">flat_ir</span><span class="o">.</span><span class="n">to_mlir</span><span class="p">(),</span>
<span class="linenos">20</span><span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos">21</span><span class="sd">            module {</span>
<span class="linenos">22</span><span class="sd">                func.func @main() -&gt; tensor&lt;?x?xf32&gt; {</span>
<span class="linenos">23</span><span class="sd">                    %c = stablehlo.constant dense&lt;[2, 3]&gt; : tensor&lt;2xi32&gt;</span>
<span class="linenos">24</span><span class="sd">                    %0 = stablehlo.dynamic_iota %c, dim = 0 : (tensor&lt;2xi32&gt;) -&gt; tensor&lt;?x?xf32&gt;</span>
<span class="linenos">25</span><span class="sd">                    return %0 : tensor&lt;?x?xf32&gt;</span>
<span class="linenos">26</span><span class="sd">                }</span>
<span class="linenos">27</span><span class="sd">            }</span>
<span class="linenos">28</span><span class="sd">            &quot;&quot;&quot;</span><span class="p">,</span>
<span class="linenos">29</span>        <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="testing-the-trace-operator-and-public-api">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Testing The Trace Operator And Public API</a><a class="headerlink" href="#testing-the-trace-operator-and-public-api" title="Link to this heading">¶</a></h3>
<p>Since we implemented our <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operator and public API in
<a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/frontend/trace/ops/"><code class="docutils literal notranslate"><span class="pre">tripy/frontend/trace/ops</span></code></a>, we’ll add the test under
<a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tests/frontend/trace/ops/"><code class="docutils literal notranslate"><span class="pre">tests/frontend/trace/ops</span></code></a>.
Create a new file there called <code class="docutils literal notranslate"><span class="pre">test_theta.py</span></code>:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">import</span> <span class="nn">tripy</span> <span class="k">as</span> <span class="nn">tp</span>
<span class="linenos"> 2</span><span class="kn">from</span> <span class="nn">tests</span> <span class="kn">import</span> <span class="n">helper</span>
<span class="linenos"> 3</span><span class="kn">from</span> <span class="nn">tripy.frontend.trace.ops</span> <span class="kn">import</span> <span class="n">Theta</span>
<span class="linenos"> 4</span>
<span class="linenos"> 5</span>
<span class="linenos"> 6</span><span class="k">class</span> <span class="nc">TestTheta</span><span class="p">:</span>
<span class="linenos"> 7</span>    <span class="c1"># This ensures that the public API function creates a frontend `Tensor`</span>
<span class="linenos"> 8</span>    <span class="c1"># and populates it with the right `Trace` operator.</span>
<span class="linenos"> 9</span>    <span class="k">def</span> <span class="nf">test_op_func</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">10</span>        <span class="n">a</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">theta</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="linenos">11</span>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<span class="linenos">12</span>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">trace_tensor</span><span class="o">.</span><span class="n">producer</span><span class="p">,</span> <span class="n">Theta</span><span class="p">)</span>
<span class="linenos">13</span>
<span class="linenos">14</span>    <span class="c1"># You should also include negative tests for anything that is expected to</span>
<span class="linenos">15</span>    <span class="c1"># fail. In our case, we just have `test_invalid_dim`,</span>
<span class="linenos">16</span>    <span class="c1"># which ensures that we emit an error if the `dim` parameter is outside</span>
<span class="linenos">17</span>    <span class="c1"># the allowed range.</span>
<span class="linenos">18</span>    <span class="k">def</span> <span class="nf">test_invalid_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">19</span>        <span class="k">with</span> <span class="n">helper</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="n">tp</span><span class="o">.</span><span class="n">TripyException</span><span class="p">,</span> <span class="n">match</span><span class="o">=</span><span class="s2">&quot;iota dimension cannot go beyond the output rank or be negative.&quot;</span><span class="p">):</span>
<span class="linenos">20</span>            <span class="n">tp</span><span class="o">.</span><span class="n">theta</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="integration-tests">
<h3><a class="toc-backref" href="#id13" role="doc-backlink">Integration Tests</a><a class="headerlink" href="#integration-tests" title="Link to this heading">¶</a></h3>
<p>The code examples in the docstring of the public API serve as good sanity integration tests.
However, you should still add separate integration tests to get better coverage.</p>
<p>Our docstring covers the 1D case, so let’s add an integration test to cover the multidimensional case.
Create a new file called <code class="docutils literal notranslate"><span class="pre">test_theta.py</span></code> under <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tests/integration/"><code class="docutils literal notranslate"><span class="pre">tests/integration</span></code></a>:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="linenos"> 2</span><span class="kn">import</span> <span class="nn">cupy</span> <span class="k">as</span> <span class="nn">cp</span>
<span class="linenos"> 3</span>
<span class="linenos"> 4</span><span class="kn">import</span> <span class="nn">tripy</span> <span class="k">as</span> <span class="nn">tp</span>
<span class="linenos"> 5</span>
<span class="linenos"> 6</span>
<span class="linenos"> 7</span><span class="k">def</span> <span class="nf">test_multi_dimensional</span><span class="p">():</span>
<span class="linenos"> 8</span>    <span class="n">output</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">theta</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos"> 9</span>    <span class="n">expected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="linenos">10</span>
<span class="linenos">11</span>    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span> <span class="n">expected</span><span class="p">)</span>
<span class="linenos">12</span>
</pre></div>
</div>
</section>
</section>
<section id="done">
<h2><a class="toc-backref" href="#id14" role="doc-backlink">Done!</a><a class="headerlink" href="#done" title="Link to this heading">¶</a></h2>
<p>If you’ve reached this point, you have successfully added a new operation to
Tripy. Congratulations!</p>
</section>
</section>

</article>
        
          <aside class="nftt-toc">
            <div class="mt-3 mb-1 my-lg-0 ps-xl-3 text-muted">
              <button class="btn btn-link link-dark p-md-0 mb-2 mb-md-0 text-decoration-none nftt-toc-toggle d-md-none" type="button" data-bs-toggle="collapse" data-bs-target="#tocContents" aria-expanded="false" aria-controls="tocContents"
              >On this page <i class="ms-2 bi bi-chevron-expand"></i></button>
              <div class="title d-none d-md-block">
                <i class="bi bi-file-earmark-text"></i>&nbsp;&nbsp;<span class="small">On this page</span>
              </div>
              <hr class="d-none d-md-block my-2">
              <div class="collapse nftt-toc-collapse" id="tocContents">
                <nav id="TableOfContents">
                  <ul>
<li><a class="reference internal" href="#">Adding New Operators</a><ul>
<li><a class="reference internal" href="#implementation">Implementation</a><ul>
<li><a class="reference internal" href="#flatir-operator"><code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> Operator</a></li>
<li><a class="reference internal" href="#exposing-the-operator">Exposing The Operator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#trace-operator-and-the-public-api"><code class="docutils literal notranslate"><span class="pre">Trace</span></code> Operator And The Public API</a><ul>
<li><a class="reference internal" href="#trace-operator"><code class="docutils literal notranslate"><span class="pre">Trace</span></code> Operator</a></li>
<li><a class="reference internal" href="#public-api">Public API</a></li>
<li><a class="reference internal" href="#id1">Exposing The Operator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#testing">Testing</a><ul>
<li><a class="reference internal" href="#testing-the-flatir-operator">Testing The <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> Operator</a></li>
<li><a class="reference internal" href="#testing-the-trace-operator-and-public-api">Testing The Trace Operator And Public API</a></li>
<li><a class="reference internal" href="#integration-tests">Integration Tests</a></li>
</ul>
</li>
<li><a class="reference internal" href="#done">Done!</a></li>
</ul>
</li>
</ul>

                </nav>
              </div>
            </div>
          </aside>
        
      </main>
    </div>

    <footer class="nftt-footer">
      <nav id="paginator" class="py-4" aria-label="Documentation navigation">
    <div class="container">
      <ul class="pagination justify-content-between mb-0"><li class="page-item">
            <a href="design-decisions.html" class="d-flex px-5 align-items-end" rel="prev" aria-label="Previous page: Design Decisions">
              <span class="prev-page"><i class="bi bi-caret-left"></i></span>
              <div class="d-flex flex-column">
                <span class="text-small text-start text-muted">Previous</span>
                <span class="underline">Design Decisions</span>
              </div>
            </a>
          </li>
        <li class="page-item ms-auto">
            <a href="mlir-dialect-python-apis.html" class="d-flex px-5 align-items-end" rel="next" aria-label="Next page: Using Python APIs of MLIR Dialects">
              <div class="d-flex flex-column">
                <span class="text-small text-end text-start text-muted">Next</span>
                <span class="underline">Using Python APIs of MLIR Dialects</span>
              </div>
              <span class="next-page"><i class="bi bi-caret-right"></i></span>
            </a>
          </li>
        
      </ul>
    </div>
  </nav>

      <div class="py-5 px-4 px-md-3">
  <div class="container">
    

    <div class="row">
      <div class="col-lg-12 text-center">
        <a class="brand-text d-inline-flex align-items-center mb-2 text-decoration-none" href="/" aria-label="Nefertiti-for-Sphinx">
          <span class="fs-6 fw-bold">Tripy</span>
        </a>
        
          <ul class="list-unstyled small text-muted">
            <li>2024, NVIDIA</li>
          </ul>
        
        
      </div>
    </div>
  </div>
</div>
    </footer>
    <script src="../_static/documentation_options.js?v=d45e8c67"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>

    <script type="text/javascript" src="../_static/bootstrap.bundle.min.js"></script>
    <script type="text/javascript" src="../_static/sphinx-nefertiti.min.js"></script>
    
  </body>
</html>