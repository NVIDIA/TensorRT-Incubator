

<!DOCTYPE html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="docsearch:name" content="Tripy" />
    <meta name="docsearch:package_type" content="" />
    <meta name="docsearch:release" content="0.0.1" />
    <meta name="docsearch:version" content="0.0.1" />
    
      <title>Architecture &mdash; Tripy 0.0.1 documentation</title>
    
    <link rel="stylesheet" href="../../_static/bootstrap-icons.css" type="text/css" />
          <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=3d3fbe02" />
          <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
          <link id="pygments_dark_css" media="(prefers-color-scheme: dark)" rel="stylesheet" type="text/css" href="../../_static/pygments_dark.css?v=b20cc3f5" />
          <link rel="stylesheet" type="text/css" href="../../_static/colorsets/sphinx-nefertiti-green.min.css" />
          <link rel="stylesheet" type="text/css" href="../../_static/fonts/nunito/stylesheet.css" />
          <link rel="stylesheet" type="text/css" href="../../_static/fonts/red-hat-mono/stylesheet.css" />
          <link rel="stylesheet" type="text/css" href="../../_static/pygments_dark.css?v=b20cc3f5" />
          <link rel="stylesheet" type="text/css" href="../../_static/style.css?v=270043a8" />
        <link rel="index" title="Index" href="../../genindex.html" />
        <link rel="search" title="Search" href="../../search.html" />
        <link rel="top" title="Tripy 0.0.1 documentation" href="#" />
    <style>
      :root {
        --nftt-body-font-family: "Nunito", var(--nftt-font-sans-serif) !important;
        --nftt-font-monospace: "Red Hat Mono", var(--nftt-font-family-monospace) !important;
        --nftt-project-name-font: var(--nftt-body-font-family);
        --nftt-documentation-font: var(--nftt-body-font-family);
        --nftt-doc-headers-font: "Georgia", var(--nftt-documentation-font);--nftt-documentation-font-size: 1.0rem;--nftt-monospace-font-size: 0.85rem;}
      h1 *, h2 *, h3 *, h4 *, h5 *, h6 * { font-size: inherit; }
    </style>
  </head>
  <body>
    <header class="navbar navbar-expand-lg navbar-dark nftt-navbar flex-column fixed-top">
      <div class="skip-links container-xxl visually-hidden-focusable overflow-hidden justify-content-start">
        <div class="border-bottom mb-2 pb-2 w-100">
          <a class="d-none d-md-inline-flex p-2 m-1" href="#sidebar-filter">Skip to docs navigation</a>
          <a class="d-inline-flex p-2 m-1" href="#content">Skip to main content</a>
        </div>
      </div>
      <nav class="container-xxl nftt-gutter flex-wrap flex-lg-nowrap" aria-label="Main navigation">
        <div class="nftt-navbar-toggler">
          <button class="navbar-toggler p-2" type="button" data-bs-toggle="offcanvas" data-bs-target="#sidebar" aria-controls="sidebar" aria-label="Toggle documentation navigation">
            <i class="bi bi-list"></i>
          </button>
        </div>
          <a href="../../index.html"
              
              class="navbar-brand p-0 me-0 md-lg-2"
          ><span class="brand-text">Tripy</span></a>
        
        <div class="d-flex d-lg-none">
          <button class="navbar-toggler p-2" type="button" data-bs-toggle="offcanvas" data-bs-target="#nfttSearch" aria-controls="nfttSearch" aria-label="Search">
            <i class="bi bi-search"></i>
          </button>
          <button class="navbar-toggler p-2" type="button" data-bs-toggle="offcanvas" data-bs-target="#nfttNavbar" aria-controls="nfttNavbar" aria-label="Toggle navigation">
            <i class="bi bi-three-dots"></i>
          </button>
        </div>
        
<div class="offcanvas-lg offcanvas-end flex-grow-1" tabindex="-1" id="nfttSearch" aria-labelledby="nfttSearchOffcanvasLabel" data-bs-scroll="true">
  <div class="offcanvas-header px-4 pb-0">
    <h5 class="offcanvas-title fw-bold" id="nfttSearchOffcanvasLabel">Search the documentation</h5>
    <button type="button" class="btn-close" data-bs-dismiss="offcanvas" aria-label="Close" data-bs-target="#nfttSearch"></button>
  </div>
  <div class="offcanvas-body p-4 pt-0 p-lg-0 px-lg-3">
    <hr class="d-lg-none text-white-50">
    <ul class="navbar-nav flex-row align-items-center flex-wrap ms-md-auto">
      <li class="nav-item col-12 col-lg-auto">
        <form id="nftt-search-form" action="../../search.html" method="get">
          <div class="input-group">
            <input type="text" name="q" class="form-control" placeholder="Search docs" aria-label="Search" aria-describedby="button-search">
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
            <button class="btn btn-primary" type="submit" id="button-search" aria-label="Search"><i class="bi bi-search"></i></button>
          </div>
        </form>
      </li>
    </ul>
  </div>
</div>

        <div class="offcanvas-lg offcanvas-end" tabindex="-1" id="nfttNavbar" aria-labelledby="nfttNavbarOffcanvasLabel" data-bs-scroll="true">
          <div class="offcanvas-header px-4 pb-0">
            <div class="offcanvas-title text-white fw-bold" id="nfttNavbarOffcanvasLabel"><span class="brand-text">Nefertiti for Sphinx</span></div>
            <button type="button" class="btn-close btn-close-white" data-bs-dismiss="offcanvas" aria-label="Close" data-bs-target="#nfttNavbar"></button>
          </div>
          <div class="offcanvas-body p-4 pt-0 p-lg-0">
            <hr class="d-lg-none text-white-50">
            <ul class="navbar-nav flex-row align-items-center flex-wrap ms-md-auto">
              
              <li class="nav-item col-12 col-lg-auto">
                <a class="nav-link py-2 py-lg-0 px-0 px-lg-2" href="https://github.com/NVIDIA/TensorRT-Incubator" target="_blank" rel="noopener">
                  <div class="d-flex align-items-center">
                    <div class="me-2">
                      <i class="bi bi-git size-24"></i>
                    </div>
                    <div class="repo d-flex flex-column align-items-center" data-snftt-repo-url="https://github.com/NVIDIA/TensorRT-Incubator">
                      Tripy
                      <div class="d-flex justify-content-center" data-snftt-repo-metrics>
                        <span class="pe-2 d-flex justify-content-center align-items-center">
                          <i class="bi bi-tag size-14"></i>
                          <span class="repo-metric" data-snftt-repo-tag></span>
                        </span>
                        <span class="pe-2 d-flex justify-content-center align-items-center">
                          <i class="bi bi-star size-14"></i>
                          <span class="repo-metric" data-snftt-repo-stars></span>
                        </span>
                        <span class="d-flex justify-content-center align-items-center">
                          <i class="bi bi-diagram-2 size-14"></i>
                          <span class="repo-metric" data-snftt-repo-forks></span>
                        </span>
                      </div>
                    </div>
                  </div>
                </a>
              </li>
              <li class="nav-item col-12 col-lg-auto h-100" aria-hidden="true">
                <div class="vr d-none d-lg-flex h-100 mx-lg-2 text-white"></div>
                <hr class="d-lg-none text-white-50">
              </li>
              
              <!-- version_dropdown.html -->

              
              <!-- colorscheme_dropdown.html -->
<li class="nav-item dropdown">
  <a class="nav-link d-flex py-2 px-0 px-lg-2 dropdown-toggle align-items-center" id="snftt-luz" href="#" data-bs-toggle="dropdown" data-bs-display="static" aria-expanded="false" aria-label="Toggle light/dark">
    <i class="bi bi-circle-half" data-snftt-luz-icon-active></i>
    <span id="snftt-luz-text" class="d-lg-none small ms-2">Toggle light/dark</span>
  </a>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="snftt-luz-text">
    <li>
      <h6 class="dropdown-header">Light/dark</h6>
    </li>
    <li>
      <a class="dropdown-item d-flex align-items-center" data-snftt-luz="light" href="#" aria-pressed="false">
        <span class="small">
          <i class="bi bi-sun" data-snftt-luz-icon="light"></i>
        </span>
        <span class="small ms-3">Light</span>
        <i class="bi bi-check ms-auto"></i>
      </a>
    </li>
    <li>
      <a class="dropdown-item d-flex align-items-center" data-snftt-luz="dark" href="#" aria-pressed="false">
        <span class="small">
          <i class="bi bi-moon-stars" data-snftt-luz-icon="dark"></i>
        </span>
        <span class="small ms-3">Dark</span>
        <i class="bi bi-check ms-auto"></i>
      </a>
    </li>
    <li>
      <a class="dropdown-item current d-flex align-items-center" data-snftt-luz="default" href="#" aria-pressed="false">
        <span class="small">
          <i class="bi bi-circle-half" data-snftt-luz-icon="default"></i>
        </span>
        <span class="small ms-3">Default</span>
        <i class="bi bi-check ms-auto"></i>
      </a>
    </li>
  </ul>
</li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <div class="container-xxl nftt-gutter nftt-layout">
      <aside class="nftt-sidebar">
        <div class="title d-none d-md-block">
          <i class="bi bi-book"></i>&nbsp;&nbsp;<span>Table of contents</span>
        </div>
        <div id="sidebar" tabindex="-1" class="offcanvas-lg offcanvas-start" aria-labelledby="nfttSidebarOffcanvasLabel">
            <!-- danirus sidebartemplate: "globaltoc.html" --><div class="offcanvas-header border-bottom">
  <h5 class="offcanvas-title" id="nfttSidebarOffcanvasLabel">
    Table of contents
  </h5>
  <button type="button" class="btn-close" data-bs-dismiss="offcanvas" aria-label="Close" data-bs-target="#sidebar"></button>
</div>

<div class="offcanvas-body">
  <nav class="toc" aria-label="Main menu">
    <div class="mb-3 p-1 pt-3 pb-4 border-bottom">
      <input id="sidebar-filter" type="text" name="filter" class="form-control form-control-sm" placeholder="filter" aria-label="filter">
    </div>
    <p class="caption" role="heading"><span class="caption-text">User Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../pre0_user_guides/introduction-to-tripy.html">An Introduction To Tripy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pre0_user_guides/quantization.html">Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../compiler/index.html">Compiler</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../compiler/arg_info.html">ArgInfo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../compiler/executable.html">Executable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../compiler/input_info.html">InputInfo</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../config.html">config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../datatype.html">dtype</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../device.html">device</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../exception/index.html">Exception</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../exception/tripy_exception.html">TripyException</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../logger.html">logger</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules/index.html">Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../modules/conv.html">Conv</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../modules/conv_transpose.html">ConvTranspose</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../modules/embedding.html">Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../modules/group_norm.html">GroupNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../modules/layer_norm.html">LayerNorm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../modules/linear.html">Linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../modules/parameter.html">Parameter</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../shape.html">Shape</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor/index.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_operations/index.html">Tensor Operations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/abs.html">abs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/all.html">all</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/allclose.html">allclose</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/any.html">any</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/arange.html">arange</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/argmax.html">argmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/argmin.html">argmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/cast.html">cast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/concatenate.html">concatenate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/copy.html">copy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/cos.html">cos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/dequantize.html">dequantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/exp.html">exp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/expand.html">expand</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/flip.html">flip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/full.html">full</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/full_like.html">full_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/gather.html">gather</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/gelu.html">gelu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/iota.html">iota</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/iota_like.html">iota_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/log.html">log</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/masked_fill.html">masked_fill</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/max.html">max</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/maximum.html">maximum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/mean.html">mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/minimum.html">minimum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/ones.html">ones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/ones_like.html">ones_like</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/permute.html">permute</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/plugin.html">plugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/prod.html">prod</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/quantize.html">quantize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/relu.html">relu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/reshape.html">reshape</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/rsqrt.html">rsqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/sigmoid.html">sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/silu.html">silu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/sin.html">sin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/softmax.html">softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/split.html">split</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/sqrt.html">sqrt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/squeeze.html">squeeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/sum.html">sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/tanh.html">tanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/transpose.html">transpose</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/tril.html">tril</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/triu.html">triu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/unsqueeze.html">unsqueeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/var.html">var</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/where.html">where</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/zeros.html">zeros</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tensor_operations/zeros_like.html">zeros_like</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../post0_developer_guides/architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../post0_developer_guides/debugging.html">Debugging MLIR-TensorRT backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../post0_developer_guides/design-decisions.html">Design Decisions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../post0_developer_guides/how-to-add-new-ops.html">Adding New Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../post0_developer_guides/mlir-dialect-python-apis.html">Using Python APIs of MLIR Dialects</a></li>
</ul>

  </nav>
  <template data-toggle-item-template>
    <button class="btn btn-sm btn-link toctree-expand" type="button">
      <i class="bi bi-caret-right"></i>
      <span class="visually-hidden">Toggle menu contents</span>
    </button>
  </template>
</div>
        </div>
      </aside>
      <main class="nftt-main">
        <article id="content" class="nftt-content" role="main">
    <section id="architecture">
<h1><a class="toc-backref" href="#id1" role="doc-backlink">Architecture</a><a class="headerlink" href="#architecture" title="Link to this heading">¶</a></h1>
<p>This document explains the overall architecture of Tripy.</p>
<nav class="contents" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#architecture" id="id1">Architecture</a></p>
<ul>
<li><p><a class="reference internal" href="#overview" id="id2">Overview</a></p>
<ul>
<li><p><a class="reference internal" href="#trace" id="id3">Trace</a></p></li>
<li><p><a class="reference internal" href="#flatir" id="id4">FlatIR</a></p></li>
<li><p><a class="reference internal" href="#mlir" id="id5">MLIR</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#a-day-in-the-life-of-a-tripy-tensor" id="id6">A Day In The Life Of A Tripy Tensor</a></p>
<ul>
<li><p><a class="reference internal" href="#tracing" id="id7">Tracing</a></p></li>
<li><p><a class="reference internal" href="#evaluation" id="id8">Evaluation</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
<section id="overview">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Overview</a><a class="headerlink" href="#overview" title="Link to this heading">¶</a></h2>
<p>The main technical requirement of Tripy is twofold:</p>
<ol class="arabic simple">
<li><p>We must be able to provide a Pythonic, functional style interface to the user.</p></li>
<li><p>We must be able to provide a computation graph to the compiler.</p></li>
</ol>
<p>Tripy uses a series of intermediate representations to solve this problem.
Below is a diagram of how these IRs are connected to each other:</p>
<div class="mermaid">
            graph TD
    subgraph &quot;Python&quot;
        subgraph &quot;Frontend&quot;
            A[Tripy Python API] --&gt;|Stage Out| B[Trace]
        end

        subgraph &quot;Flat IR&quot;
            B --&gt; C[FlatIR]
        end

        subgraph &quot;Backend&quot;
            C --&gt; D[MLIR StableHLO]
        end
    end

    subgraph &quot;C++&quot;
        D --&gt; E[MLIR-TRT];
    end
        </div><section id="trace">
<h3><a class="toc-backref" href="#id3" role="doc-backlink">Trace</a><a class="headerlink" href="#trace" title="Link to this heading">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">Trace</span></code> is meant to provide a 1:1 graph representation of the user’s Python code.
It is a bipartite graph consisting of Trace <code class="docutils literal notranslate"><span class="pre">Operation</span></code>s and <code class="docutils literal notranslate"><span class="pre">TraceTensor</span></code>s - each Trace <code class="docutils literal notranslate"><span class="pre">Operation</span></code>
is connected to input/output <code class="docutils literal notranslate"><span class="pre">TraceTensor</span></code>s and each <code class="docutils literal notranslate"><span class="pre">TraceTensor</span></code> has knowledge of its
producer Trace <code class="docutils literal notranslate"><span class="pre">Operation</span></code>.</p>
</section>
<section id="flatir">
<h3><a class="toc-backref" href="#id4" role="doc-backlink">FlatIR</a><a class="headerlink" href="#flatir" title="Link to this heading">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> is a lower level representation that provides a 1:1 mapping to MLIR operations.
Like the <code class="docutils literal notranslate"><span class="pre">Trace</span></code>, it is a bipartite graph consisting of FlatIR <code class="docutils literal notranslate"><span class="pre">Operation</span></code>s and <code class="docutils literal notranslate"><span class="pre">FlatIRTensor</span></code>s.</p>
</section>
<section id="mlir">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">MLIR</a><a class="headerlink" href="#mlir" title="Link to this heading">¶</a></h3>
<p>The final representation before we hand off to the compiler is the MLIR itself, which, in our case,
consists primarily of StableHLO operations but can also include other dialects for certain operations.</p>
</section>
</section>
<section id="a-day-in-the-life-of-a-tripy-tensor">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">A Day In The Life Of A Tripy Tensor</a><a class="headerlink" href="#a-day-in-the-life-of-a-tripy-tensor" title="Link to this heading">¶</a></h2>
<p>To understand these components better, let’s take a look at what happens when we write a simple
program like:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="n">inp</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="linenos">2</span><span class="n">out</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="linenos">3</span><span class="n">out</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<section id="tracing">
<h3><a class="toc-backref" href="#id7" role="doc-backlink">Tracing</a><a class="headerlink" href="#tracing" title="Link to this heading">¶</a></h3>
<p>We’ll start with the first line:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="n">inp</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<section id="where-do-tp-full-and-tp-tanh-come-from">
<h4>Where Do <code class="docutils literal notranslate"><span class="pre">tp.full()</span></code> and <code class="docutils literal notranslate"><span class="pre">tp.tanh()</span></code> Come From?<a class="headerlink" href="#where-do-tp-full-and-tp-tanh-come-from" title="Link to this heading">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">tp.full()</span></code> and <code class="docutils literal notranslate"><span class="pre">tp.tanh()</span></code> APIs are part of the frontend and like other frontend functions, map to one or more
(just one in this case) <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operations. For frontend functions that map to exactly one <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operation,
we define the function directly alongside the corresponding <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operation.
In this case, the <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/frontend/trace/ops/fill.py"><code class="docutils literal notranslate"><span class="pre">Fill</span></code> operation</a> provides <code class="docutils literal notranslate"><span class="pre">tp.full()</span></code> and
the <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/frontend/trace/ops/unary_elementwise.py"><code class="docutils literal notranslate"><span class="pre">UnaryElementwise</span></code> operation</a> provides <code class="docutils literal notranslate"><span class="pre">tp.tanh()</span></code>.</p>
<p><em>We organize it this way to reduce the number of files that need to be touched when adding new ops.</em>
<em>If an operation is composed of multiple <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operations, the frontend function can be</em>
<em>defined under the <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/frontend/ops"><code class="docutils literal notranslate"><span class="pre">frontend/ops</span></code></a> submodule instead.</em></p>
</section>
<section id="what-does-it-do">
<h4>What Does It Do?<a class="headerlink" href="#what-does-it-do" title="Link to this heading">¶</a></h4>
<p>Tripy uses a lazy evaluation model; that means that computation doesn’t happen immediately when you call a function
like <code class="docutils literal notranslate"><span class="pre">tp.full()</span></code> or <code class="docutils literal notranslate"><span class="pre">tp.tanh()</span></code>. Instead, all we do is create a frontend <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> object which contains a <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operation.
The <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operation includes inputs and outputs in the form of <code class="docutils literal notranslate"><span class="pre">TraceTensor</span></code>s and is essentially just a symbolic
representation of the computation that needs to be done.</p>
<p>As we call other functions that use this frontend <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, we connect new <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operations to its output
<code class="docutils literal notranslate"><span class="pre">TraceTensor</span></code>s. You can think of this as iteratively building up an implicit graph.</p>
</section>
<section id="the-implicit-frontend-graph">
<h4>The Implicit Frontend Graph<a class="headerlink" href="#the-implicit-frontend-graph" title="Link to this heading">¶</a></h4>
<p>As mentioned before, as you create new frontend <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>s, we build up an implicit graph comprised
of <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operations and <code class="docutils literal notranslate"><span class="pre">TraceTensor</span></code>s.</p>
<p>After running both of these lines, our implicit graph will look something like this:</p>
<div class="mermaid">
            graph TD
    subgraph &quot;'inp' Tensor&quot;
        A[Fill] --&gt; B(trace_tensor0)
    end

    subgraph &quot;'out' Tensor&quot;
        B --&gt; C[UnaryElementwise]
        C --&gt; D(trace_tensor1)
    end
        </div></section>
</section>
<section id="evaluation">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Evaluation</a><a class="headerlink" href="#evaluation" title="Link to this heading">¶</a></h3>
<p>The bulk of the real work happens once we reach the final line:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="n">out</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<p>As mentioned before, Tripy uses a lazy evaluation model where a tensor is only evaluated when it is used.
A tensor is considered “used” when, for example:</p>
<ul class="simple">
<li><p>We interoperate with another framework (e.g. <code class="docutils literal notranslate"><span class="pre">torch.from_dlpack(out)</span></code> or <code class="docutils literal notranslate"><span class="pre">np.from_dlpack(out)</span></code>)</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">__repr__</span></code> is called (e.g. if we <code class="docutils literal notranslate"><span class="pre">print(out)</span></code>)</p></li>
<li><p>We explicitly call <code class="docutils literal notranslate"><span class="pre">eval()</span></code> as we’re doing here.</p></li>
</ul>
<p>In order to actually evaluate the tensor, a few different things need to happen:</p>
<section id="building-the-trace">
<h4>Building The Trace<a class="headerlink" href="#building-the-trace" title="Link to this heading">¶</a></h4>
<p>We start by building up the <code class="docutils literal notranslate"><span class="pre">Trace</span></code>. Since each frontend <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> contains a <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operation that’s already
connected with the <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operations in other tensors, we just need to walk backwards from the output tensor,
collecting trace operations as we go.</p>
<p>Here’s the textual representation for the <code class="docutils literal notranslate"><span class="pre">Trace</span></code> from our example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">t0</span> <span class="o">=</span> <span class="n">storage</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">gpu</span><span class="p">:</span><span class="mi">0</span><span class="p">)</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">fill</span><span class="p">(</span><span class="n">t0</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">output_rank</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
<span class="n">t4</span> <span class="o">=</span> <span class="n">unaryelementwise</span><span class="p">(</span><span class="n">t2</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="n">Kind</span><span class="o">.</span><span class="n">TANH</span><span class="p">)</span>
<span class="n">outputs</span><span class="p">:</span>
    <span class="n">t4</span><span class="p">:</span> <span class="p">[</span><span class="n">rank</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="p">(</span><span class="n">float32</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="n">gpu</span><span class="p">:</span><span class="mi">0</span><span class="p">)]</span>
</pre></div>
</div>
<p>When we’ve built up the complete trace, we run rank, data type, and device inference. This is why the
output tensor in the trace has its <code class="docutils literal notranslate"><span class="pre">rank</span></code>, <code class="docutils literal notranslate"><span class="pre">dtype</span></code>, and <code class="docutils literal notranslate"><span class="pre">loc</span></code> fields populated.</p>
</section>
<section id="lowering-to-flatir">
<h4>Lowering To FlatIR<a class="headerlink" href="#lowering-to-flatir" title="Link to this heading">¶</a></h4>
<p>Once we have the <code class="docutils literal notranslate"><span class="pre">Trace</span></code>, we lower it into <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code>. <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> is a very thin layer which provides a 1:1
mapping with the MLIR dialects we use.</p>
<p>To perform the lowering, each <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operation implements <code class="docutils literal notranslate"><span class="pre">to_flat_ir()</span></code>, which generates a subgraph with
one or more <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> operations.</p>
<p>Here’s a snippet for how you might implement <code class="docutils literal notranslate"><span class="pre">tanh</span></code> (the actual implementation differs,
but this is good enough for a conceptual understanding):</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="k">def</span> <span class="nf">to_flat_ir</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
<span class="linenos">2</span>    <span class="kn">from</span> <span class="nn">tripy.flat_ir.ops</span> <span class="kn">import</span> <span class="n">TanhOp</span>
<span class="linenos">3</span>
<span class="linenos">4</span>    <span class="n">TanhOp</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
</pre></div>
</div>
<p>Wait a second - what’s happening here? The function doesn’t return anything; in fact, it doesn’t appear to be doing
anything at all!</p>
<p>The way this works is as follows: when we call <code class="docutils literal notranslate"><span class="pre">to_flat_ir()</span></code> we provide input and output
<a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/flat_ir/tensor.py"><code class="docutils literal notranslate"><span class="pre">FlatIRTensor</span></code></a>s. <code class="docutils literal notranslate"><span class="pre">to_flat_ir()</span></code> is responsible for generating a
subgraph of <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> operations that bind to these inputs and outputs. The
<a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/flat_ir/ops/base.py"><code class="docutils literal notranslate"><span class="pre">BaseFlatIROp</span></code> build function</a> updates the producer of the output tensors,
meaning that <em>just building a <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> operation is enough to add it to the subgraph</em>. Once this binding
is done, we take the resulting subgraph and inline it into the <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code>, remapping the I/O tensors to those
that already exist in the <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code>.</p>
<p>Here’s the textual representation for the <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> from our example; you’ll notice that we have more operations
now than we did in the trace:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">t0</span><span class="p">:</span> <span class="p">[</span><span class="n">rank</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">((</span><span class="mi">2</span><span class="p">,)),</span> <span class="n">dtype</span><span class="o">=</span><span class="p">(</span><span class="n">int32</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="n">gpu</span><span class="p">:</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="n">ConstantOp</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">t_inter3</span><span class="p">:</span> <span class="p">[</span><span class="n">rank</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="p">(</span><span class="n">float32</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="n">gpu</span><span class="p">:</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="n">ConstantOp</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">t2</span><span class="p">:</span> <span class="p">[</span><span class="n">rank</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="p">(</span><span class="n">float32</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="n">gpu</span><span class="p">:</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="n">DynamicBroadcastOp</span><span class="p">(</span><span class="n">t_inter3</span><span class="p">,</span> <span class="n">t0</span><span class="p">,</span> <span class="n">broadcast_dim</span><span class="o">=</span><span class="p">[])</span>
<span class="n">t4</span><span class="p">:</span> <span class="p">[</span><span class="n">rank</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="p">(</span><span class="n">float32</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="n">gpu</span><span class="p">:</span><span class="mi">0</span><span class="p">)]</span> <span class="o">=</span> <span class="n">TanhOp</span><span class="p">(</span><span class="n">t2</span><span class="p">)</span>
<span class="n">outputs</span><span class="p">:</span>
    <span class="n">t4</span><span class="p">:</span> <span class="p">[</span><span class="n">rank</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="p">(</span><span class="n">float32</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="n">gpu</span><span class="p">:</span><span class="mi">0</span><span class="p">)]</span>
</pre></div>
</div>
</section>
<section id="lowering-to-mlir">
<h4>Lowering To MLIR<a class="headerlink" href="#lowering-to-mlir" title="Link to this heading">¶</a></h4>
<p>Our final translation step is to go from <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> into MLIR.</p>
<p>Similar to <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operations, <code class="docutils literal notranslate"><span class="pre">FlatIR</span></code> operations implement <code class="docutils literal notranslate"><span class="pre">to_mlir()</span></code> which generates MLIR operations.
Unlike <code class="docutils literal notranslate"><span class="pre">Trace</span></code> operations, this is always a 1:1 mapping.</p>
<p>Here’s a snippet for how <a class="reference external" href="https://github.com/NVIDIA/TensorRT-Incubator/tripy/-/blob/main//tripy/flat_ir/ops/tanh.py"><code class="docutils literal notranslate"><span class="pre">tanh()</span></code> is implemented</a>:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="k">def</span> <span class="nf">to_mlir</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operands</span><span class="p">):</span>
<span class="linenos">2</span>    <span class="k">return</span> <span class="p">[</span><span class="n">stablehlo</span><span class="o">.</span><span class="n">TanhOp</span><span class="p">(</span><span class="o">*</span><span class="n">operands</span><span class="p">)]</span>
</pre></div>
</div>
<p>There’s not much more to explain here, so let’s go right to the textual representation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>module @outs_t4_2 {
  func.func @main() -&gt; tensor&lt;?x?xf32&gt; {
    %c = stablehlo.constant dense&lt;[2, 3]&gt; : tensor&lt;2xi32&gt;
    %cst = stablehlo.constant dense&lt;5.000000e-01&gt; : tensor&lt;f32&gt;
    %0 = stablehlo.dynamic_broadcast_in_dim %cst, %c, dims = [] : (tensor&lt;f32&gt;, tensor&lt;2xi32&gt;) -&gt; tensor&lt;?x?xf32&gt;
    %1 = stablehlo.tanh %0 : tensor&lt;?x?xf32&gt;
    return %1 : tensor&lt;?x?xf32&gt;
  }
}
</pre></div>
</div>
</section>
<section id="compilation">
<h4>Compilation<a class="headerlink" href="#compilation" title="Link to this heading">¶</a></h4>
<p>Once we have the complete MLIR representation, we then compile it to an executable using the MLIR-TRT compiler.</p>
</section>
<section id="execution">
<h4>Execution<a class="headerlink" href="#execution" title="Link to this heading">¶</a></h4>
<p>Finally, we use the MLIR-TRT executor to launch the executable and retrieve the output tensors.
The executable returns <a class="reference external" href="https://mlir.llvm.org/docs/Dialects/MemRef/"><code class="docutils literal notranslate"><span class="pre">memref</span></code>s</a> which we then
wrap in Tripy frontend <a class="reference internal" href="../../tensor/index.html#tripy.Tensor" title="tripy.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">tripy.Tensor</span></code></a>s.</p>
</section>
</section>
</section>
</section>

</article>
        
          <aside class="nftt-toc">
            <div class="mt-3 mb-1 my-lg-0 ps-xl-3 text-muted">
              <button class="btn btn-link link-dark p-md-0 mb-2 mb-md-0 text-decoration-none nftt-toc-toggle d-md-none" type="button" data-bs-toggle="collapse" data-bs-target="#tocContents" aria-expanded="false" aria-controls="tocContents"
              >On this page <i class="ms-2 bi bi-chevron-expand"></i></button>
              <div class="title d-none d-md-block">
                <i class="bi bi-file-earmark-text"></i>&nbsp;&nbsp;<span class="small">On this page</span>
              </div>
              <hr class="d-none d-md-block my-2">
              <div class="collapse nftt-toc-collapse" id="tocContents">
                <nav id="TableOfContents">
                  <ul>
<li><a class="reference internal" href="#">Architecture</a><ul>
<li><a class="reference internal" href="#overview">Overview</a><ul>
<li><a class="reference internal" href="#trace">Trace</a></li>
<li><a class="reference internal" href="#flatir">FlatIR</a></li>
<li><a class="reference internal" href="#mlir">MLIR</a></li>
</ul>
</li>
<li><a class="reference internal" href="#a-day-in-the-life-of-a-tripy-tensor">A Day In The Life Of A Tripy Tensor</a><ul>
<li><a class="reference internal" href="#tracing">Tracing</a><ul>
<li><a class="reference internal" href="#where-do-tp-full-and-tp-tanh-come-from">Where Do <code class="docutils literal notranslate"><span class="pre">tp.full()</span></code> and <code class="docutils literal notranslate"><span class="pre">tp.tanh()</span></code> Come From?</a></li>
<li><a class="reference internal" href="#what-does-it-do">What Does It Do?</a></li>
<li><a class="reference internal" href="#the-implicit-frontend-graph">The Implicit Frontend Graph</a></li>
</ul>
</li>
<li><a class="reference internal" href="#evaluation">Evaluation</a><ul>
<li><a class="reference internal" href="#building-the-trace">Building The Trace</a></li>
<li><a class="reference internal" href="#lowering-to-flatir">Lowering To FlatIR</a></li>
<li><a class="reference internal" href="#lowering-to-mlir">Lowering To MLIR</a></li>
<li><a class="reference internal" href="#compilation">Compilation</a></li>
<li><a class="reference internal" href="#execution">Execution</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

                </nav>
              </div>
            </div>
          </aside>
        
      </main>
    </div>

    <footer class="nftt-footer">
      
<nav id="paginator"></nav>

      <div class="py-5 px-4 px-md-3">
  <div class="container">
    

    <div class="row">
      <div class="col-lg-12 text-center">
        <a class="brand-text d-inline-flex align-items-center mb-2 text-decoration-none" href="/" aria-label="Nefertiti-for-Sphinx">
          <span class="fs-6 fw-bold">Tripy</span>
        </a>
        
          <ul class="list-unstyled small text-muted">
            <li>2024, NVIDIA</li>
          </ul>
        
        
      </div>
    </div>
  </div>
</div>
    </footer>
    <script src="../../_static/documentation_options.js?v=d45e8c67"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="https://unpkg.com/mermaid@10.2.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>

    <script type="text/javascript" src="../../_static/bootstrap.bundle.min.js"></script>
    <script type="text/javascript" src="../../_static/sphinx-nefertiti.min.js"></script>
    
  </body>
</html>