{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Image Classificiation with Tripy\n",
    "\n",
    "This notebook aims to demonstrate the implementation of a ResNet50 model using `tripy`. It implements the architecture, \n",
    "loads pretrained weights, and runs classification on a few sample images from [`commet-team/coco-500`](https://huggingface.co/datasets/comet-team/coco-500) dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libaries\n",
    "Install `tripy` prebuilt wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://nvidia.github.io/TensorRT-Incubator/packages.html\n",
      "Requirement already satisfied: tripy in /tripy (0.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://nvidia.github.io/TensorRT-Incubator/packages.html\n",
      "Requirement already satisfied: tripy in /tripy (0.0.3)\n",
      "Requirement already satisfied: tensorrt~=10.0 in /usr/local/lib/python3.10/dist-packages (from tripy) (10.6.0)\n",
      "Requirement already satisfied: mlir-tensorrt-compiler==0.1.36+cuda12.trt102 in /usr/local/lib/python3.10/dist-packages (from tripy) (0.1.36+cuda12.trt102)\n",
      "Requirement already satisfied: mlir-tensorrt-runtime==0.1.36+cuda12.trt102 in /usr/local/lib/python3.10/dist-packages (from tripy) (0.1.36+cuda12.trt102)\n",
      "Requirement already satisfied: colored==2.2.3 in /usr/local/lib/python3.10/dist-packages (from tripy) (2.2.3)\n",
      "Requirement already satisfied: numpy<=1.26,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from mlir-tensorrt-compiler==0.1.36+cuda12.trt102->tripy) (1.25.0)\n",
      "Requirement already satisfied: pybind11<=2.10.3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from mlir-tensorrt-compiler==0.1.36+cuda12.trt102->tripy) (2.10.3)\n",
      "Requirement already satisfied: PyYAML<=6.0.1,>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from mlir-tensorrt-compiler==0.1.36+cuda12.trt102->tripy) (6.0.1)\n",
      "Requirement already satisfied: dataclasses<=0.8,>=0.6 in /usr/local/lib/python3.10/dist-packages (from mlir-tensorrt-compiler==0.1.36+cuda12.trt102->tripy) (0.6)\n",
      "Requirement already satisfied: tensorrt-cu12==10.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt~=10.0->tripy) (10.6.0)\n",
      "Requirement already satisfied: tensorrt-cu12-bindings==10.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt-cu12==10.6.0->tensorrt~=10.0->tripy) (10.6.0)\n",
      "Requirement already satisfied: tensorrt-cu12-libs==10.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt-cu12==10.6.0->tensorrt~=10.0->tripy) (10.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.10/dist-packages (from tensorrt-cu12-libs==10.6.0->tensorrt-cu12==10.6.0->tensorrt~=10.0->tripy) (12.6.77)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --no-index -f https://nvidia.github.io/TensorRT-Incubator/packages.html tripy --no-deps\n",
    "!pip install -f https://nvidia.github.io/TensorRT-Incubator/packages.html tripy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the `datasets` package from huggingface to load a small image dataset and perform inference using the ResNet50 image classification model on some sample images later on. `matplotlib` and `pillow` package are used at the end for plotting and visualizing the classified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets matplotlib pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "Tripy's implementation of ResNet50 introduced in the paper [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) by He et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "import tripy as tp\n",
    "\n",
    "class ResNetConvLayer(tp.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_dims: Tuple[int, int],\n",
    "        stride: Tuple[int, int] = (1, 1),\n",
    "        padding: Tuple[Tuple[int, int], Tuple[int, int]] = ((0, 0), (0, 0)),\n",
    "        activation: bool = True,\n",
    "    ):\n",
    "        \"\"\"Convolutional layer with batch normalization and optional\n",
    "        ReLU activation.\"\"\"\n",
    "        super(ResNetConvLayer, self).__init__()\n",
    "        self.convolution = tp.Conv(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_dims=kernel_dims,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.normalization = tp.BatchNorm(out_channels)\n",
    "        self.activation = activation\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        x = self.convolution(x)\n",
    "        x = self.normalization(x)\n",
    "        if self.activation:\n",
    "            x = tp.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetShortCut(tp.Module):\n",
    "    def __init__(\n",
    "        self, in_channels: int, out_channels: int, stride: Tuple[int, int]\n",
    "    ):\n",
    "        \"\"\"1x1 convolution and batch normalization for input and output channel\n",
    "        dimension matching in ResNetBottleNeckLayer.\"\"\"\n",
    "        super(ResNetShortCut, self).__init__()\n",
    "        self.convolution = tp.Conv(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_dims=(1, 1),\n",
    "            stride=stride,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.normalization = tp.BatchNorm(out_channels)\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        x = self.convolution(x)\n",
    "        x = self.normalization(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEmbeddings(tp.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Applies an initial convolution and max-pooling operation to reduce\n",
    "        dimensions and prepare input for the encoder.\n",
    "        \"\"\"\n",
    "        super(ResNetEmbeddings, self).__init__()\n",
    "        self.embedder = ResNetConvLayer(\n",
    "            3,\n",
    "            64,\n",
    "            kernel_dims=(7, 7),\n",
    "            stride=(2, 2),\n",
    "            padding=((3, 3), (3, 3)),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        x = self.embedder(x)\n",
    "        x = tp.maxpool(\n",
    "            x,\n",
    "            kernel_dims=(3, 3),\n",
    "            stride=(2, 2),\n",
    "            padding=((1, 1), (1, 1)),\n",
    "        )\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetBottleNeckLayer(tp.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bottleneck_channels: int,\n",
    "        stride: Tuple[int, int],\n",
    "    ):\n",
    "        \"\"\"Consists of a ResNetShortCut layer for dimension matching and\n",
    "        three ResNetConvLayers for residual learning.\"\"\"\n",
    "        super(ResNetBottleNeckLayer, self).__init__()\n",
    "\n",
    "        self.shortcut = (\n",
    "            ResNetShortCut(in_channels, out_channels, stride)\n",
    "            if in_channels != out_channels or stride != (1, 1)\n",
    "            else lambda x: x\n",
    "        )\n",
    "        self.layer = [\n",
    "            ResNetConvLayer(\n",
    "                in_channels,\n",
    "                bottleneck_channels,\n",
    "                kernel_dims=(1, 1),\n",
    "                stride=(1, 1),\n",
    "            ),\n",
    "            ResNetConvLayer(\n",
    "                bottleneck_channels,\n",
    "                bottleneck_channels,\n",
    "                kernel_dims=(3, 3),\n",
    "                stride=stride,\n",
    "                padding=((1, 1), (1, 1)),\n",
    "            ),\n",
    "            ResNetConvLayer(\n",
    "                bottleneck_channels,\n",
    "                out_channels,\n",
    "                kernel_dims=(1, 1),\n",
    "                stride=(1, 1),\n",
    "                activation=False,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        self.activation = tp.relu\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        identity = self.shortcut(x)\n",
    "        for layer in self.layer:\n",
    "            x = layer(x)\n",
    "        x = x + identity\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetStage(tp.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bottleneck_channels: int,\n",
    "        stride: Tuple[int, int],\n",
    "    ):\n",
    "        \"\"\"Contains multiple bottleneck layers, increasing channels and reducing\n",
    "        spatial dimensions.\"\"\"\n",
    "        super(ResNetStage, self).__init__()\n",
    "        self.layers = []\n",
    "        for i in range(num_layers):\n",
    "            layer = ResNetBottleNeckLayer(\n",
    "                in_channels if i == 0 else out_channels,\n",
    "                out_channels,\n",
    "                bottleneck_channels,\n",
    "                stride if i == 0 else (1, 1),\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetEncoder(tp.Module):\n",
    "    def __init__(\n",
    "        self, layers_config: List[Tuple[int, int, int, Tuple[int, int]]]\n",
    "    ):\n",
    "        \"\"\"Comprises multiple stages of bottleneck layers to extract abstract\n",
    "        features from the input.\"\"\"\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "        self.stages = []\n",
    "        in_channels = 64\n",
    "        for _, (\n",
    "            num_layers,\n",
    "            out_channels,\n",
    "            bottleneck_channels,\n",
    "            stride,\n",
    "        ) in enumerate(layers_config):\n",
    "            stage = ResNetStage(\n",
    "                num_layers,\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                bottleneck_channels,\n",
    "                stride,\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            in_channels = out_channels\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        for stage in self.stages:\n",
    "            x = stage(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetModel(tp.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Combines ResNetEmbeddings and ResNetEncoder to create the backbone\n",
    "        for feature extraction.\"\"\"\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.embedder = ResNetEmbeddings()\n",
    "        layers_config = [\n",
    "            (3, 256, 64, (1, 1)),\n",
    "            (4, 512, 128, (2, 2)),\n",
    "            (6, 1024, 256, (2, 2)),\n",
    "            (3, 2048, 512, (2, 2)),\n",
    "        ]\n",
    "        self.encoder = ResNetEncoder(layers_config)\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        x = self.embedder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = tp.avgpool(\n",
    "            x, kernel_dims=(7, 7), stride=(7, 7)\n",
    "        )  # output size will be (1, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetClassifier(tp.Module):\n",
    "    def __init__(self, num_classes: int = 1000):\n",
    "        \"\"\"Combines the backbone ResNetModel and a classifier head for\n",
    "        outputting class probabilities.\"\"\"\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.resnet = ResNetModel()\n",
    "        self.classifier = tp.Sequential(\n",
    "            lambda x: tp.flatten(x, start_dim=1),\n",
    "            tp.Linear(2048, num_classes),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x: tp.Tensor) -> tp.Tensor:\n",
    "        features = self.resnet(x)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripy_model = ResNetClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Weights into the Model  \n",
    "With the `tripy_model` ready, we'll load the pretrained PyTorch model [`microsoft/resnet-50`](https://huggingface.co/microsoft/resnet-50) from Hugging Face. Next, we'll copy the weights from the pretrained model's `state_dict` into the `tripy_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ResNetForImageClassification\n",
    "\n",
    "# Load the pretrained ResNet50 model from Hugging Face\n",
    "resnet_pretrained = ResNetForImageClassification.from_pretrained(\n",
    "    \"microsoft/resnet-50\"\n",
    ").to(\"cuda\") # Move the model to gpu, to avoid copies from cpu->gpu in weight loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_weights(model, pretrained_state_dict):\n",
    "    model_state_dict_keys = set(model.state_dict().keys())\n",
    "    model_dict = {}\n",
    "\n",
    "    # Convert each weight to a tp.Parameter and update the model's state dict\n",
    "    for k, v in pretrained_state_dict.items():\n",
    "        if \"num_batches_tracked\" in k:\n",
    "            continue  # Skip num_batches_tracked since it is not needed for\n",
    "            # inference (tp.BatchNorm does not support)\n",
    "\n",
    "        assert k in model_state_dict_keys\n",
    "        model_dict[k] = tp.Parameter(v.contiguous())\n",
    "\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "\n",
    "# Load pretrained weights to tripy model\n",
    "load_pretrained_weights(\n",
    "    tripy_model,\n",
    "    pretrained_state_dict=resnet_pretrained.state_dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model\n",
    "Now compile the model with `tp.compile` for faster execution. We make sure to compile both the model `forward` path and any `tripy` postprocessing such as `tp.argmax(logits)` as well to avoid running it in eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_classifier(input):\n",
    "    \"\"\"Inference function to compile. Runs forward path\n",
    "    and returns argmax of output logits.\"\"\"\n",
    "    logits = tripy_model(input)\n",
    "    return tp.argmax(logits) # We compile tp.argmax as well to avoid running it in eager mode.\n",
    "\n",
    "compiled_resnet_classifier = tp.compile(\n",
    "    resnet_classifier,\n",
    "    args=[tp.InputInfo([1, 3, 224, 224], dtype=tp.float32)], # Expected input shape and dype in inference\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "\n",
    "Now we will test our ResNet50 classification model on a few sample images from [`comet-team/coco-500`](https://huggingface.co/datasets/comet-team/coco-500) for image classification task. We first load the dataset and `AutoImageProcessor` of [`microsoft/resnet-50`](https://huggingface.co/microsoft/resnet-50) model to preprocess each image and run classification inference on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "from datasets import load_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the image dataset\n",
    "dataset = load_dataset(\"comet-team/coco-500\", split=\"train\")\n",
    "\n",
    "# Load the image processor for image preprocessing\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "# Sample image indices to classify\n",
    "idxs = [6, 44, 34, 25, 105]\n",
    "labels = [\n",
    "    \"apron\",\n",
    "    \"medicine chest, medicine cabinet\",\n",
    "    \"mountain bike, all-terrain bike, off-roader\",\n",
    "    \"lifeboat\",\n",
    "    \"disk brake, disc brake\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(idxs), figsize=(15, 3))\n",
    "\n",
    "# Loop through each index, preprocess each image and run classification inference\n",
    "for ax, nid, label in zip(axes, idxs, labels):\n",
    "    image = dataset[nid][\"Image\"]\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Preprocess the image for inference\n",
    "    processed_image = processor(image, return_tensors=\"np\")[\"pixel_values\"]\n",
    "    tp_image = tp.Tensor(\n",
    "        processed_image,\n",
    "        dtype=tp.float32,\n",
    "        device=tp.device(\"gpu\"),\n",
    "    )\n",
    "\n",
    "    # Run inference with compiled model and get predicted label\n",
    "    label_idx = compiled_resnet_classifier(tp_image)\n",
    "    predicted_label = resnet_pretrained.config.id2label[label_idx.tolist()]\n",
    "\n",
    "    assert predicted_label == label, f\"{predicted_label} vs {label}\"\n",
    "    ax.set_title(predicted_label, fontsize=10, fontweight=\"bold\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.suptitle(\n",
    "    \"Visualized ResNet50 Predictions\",\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    "    y=1.05,\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "nbreg": {
   "diff_ignore": [
    "/cells/*/outputs/",
    "/cells/*/execution_count"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
