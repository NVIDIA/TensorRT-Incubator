//===- GeluActivationPatterns.pdll ------------------------------*- PDLL -*-===//
//
// SPDX-FileCopyrightText: Copyright 2024 NVIDIA CORPORATION & AFFILIATES.
// All rights reserved.
// SPDX-License-Identifier: Apache-2.0
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
//===----------------------------------------------------------------------===//
//
// PDLL rewrites for matching GELU.
//
//===----------------------------------------------------------------------===//
#include "mlir-tensorrt-dialect/TensorRT/IR/TensorRTOps.td"


//===----------------------------------------------------------------------===//
// Constraint definitions for primitives (mul, add, etc).
// Each constraint requires 3 `Constraint` functions because of PDLL
// limitations involving concrete enum attributes...
//===----------------------------------------------------------------------===//
Constraint MulConstraintImpl(op: Op) [{
  return mlir::success(
      cast<tensorrt::ElementWiseOp>(op).getElementwiseOperation() ==
        ElementWiseOperation::kPROD
    );
}];
Constraint AddConstraintImpl(op: Op) [{
  return mlir::success(
      cast<tensorrt::ElementWiseOp>(op).getElementwiseOperation() ==
        ElementWiseOperation::kSUM
    );
}];
Constraint TanhConstraintImpl(op: Op) [{
  return mlir::success(
      cast<tensorrt::ActivationOp>(op).getActivationType() ==
        ActivationType::kTANH
    );
}];
Constraint MulConstraint(op: Op<tensorrt.element_wise>) -> Op {
  MulConstraintImpl(op);
  return op;
}
Constraint AddConstraint(op: Op<tensorrt.element_wise>) -> Op {
  AddConstraintImpl(op);
  return op;
}
Constraint TanhConstraint(op: Op<tensorrt.activation>) -> Op {
  TanhConstraintImpl(op);
  return op;
}
Constraint Mul(lhs: Value, rhs: Value) -> Op {
  return MulConstraint(op<tensorrt.element_wise>(lhs, rhs));
}
Constraint Add(lhs: Value, rhs: Value) -> Op {
  return AddConstraint(op<tensorrt.element_wise>(lhs, rhs));
}
Constraint Tanh(x: Value) -> Op {
  return TanhConstraint(op<tensorrt.activation>(x));
}

/// Is true if `x` is a constant op that has a splat constant
/// where splat element is equal to `attr`.
Constraint SplatElements(x: Op, attr: Attr) [{
  DenseElementsAttr els{};
  if(!matchPattern(x, m_Constant(&els)))
    return failure();
  if(!els.isSplat())
    return failure();
  Attribute value = els.getSplatValue<Attribute>();
  return success(value == attr);
}];

/// We need a native C++ function since we can't create the right
/// enum type in PDLL.
Rewrite CreateGeluTanh(x: Value) -> Op [{
  return rewriter.create<tensorrt::ActivationOp>(x.getLoc(),
    x, ActivationType::kGELU_TANH, FloatAttr{}, FloatAttr{}
  );
}];

Constraint TypesMatch(x: Value, y: Value) [{
  return success(x.getType() == y.getType());
}];

/// Raise a sequence of "approximate" GELU to `tensorrt.ext.gelu_tanh`.
/// See
/// `https://github.com/google/jax/blob/main/jax/_src/nn/functions.py#L424-L455`.
Pattern RaiseToGeluTanh {
  let x: Value;
  let const0 = op<tensorrt.constant>();
  SplatElements(const0, attr<"4.471500e-02 : f32">);
  let rootPiOverTwo = op<tensorrt.constant>();
  SplatElements(rootPiOverTwo, attr<"0.797884583 : f32">);
  let one = op<tensorrt.constant>();
  SplatElements(one, attr<"1.0 : f32">);
  let half = op<tensorrt.constant>();
  SplatElements(half, attr<"0.5 : f32">);
  let scaledCube = Mul(Mul(Mul(x, x), x), const0);
  let tanArg = Mul(Add(x, scaledCube), rootPiOverTwo);
  let inner = Add(Tanh(tanArg), one);
  let root = Mul(x, Mul(inner, half));

  // Sanity check for cases where we could have broadcasted x.
  TypesMatch(root, x);

  rewrite root with {
    let replacement = CreateGeluTanh(x);
    replace root with replacement;
  };
}
